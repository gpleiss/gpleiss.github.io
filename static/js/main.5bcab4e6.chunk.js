(this["webpackJsonpgeoffpleiss.com"]=this["webpackJsonpgeoffpleiss.com"]||[]).push([[0],{27:function(e){e.exports=JSON.parse('[{"id":"misakiewicz2023six","title":"Six Lectures on Linearized Neural Networks","authors":"Theodor Misiakiewicz, Andrea Montanari","year":2023,"url":"https://arxiv.org/abs/2308.13431","tags":["resource"]},{"id":"bach2024learning","title":"Learning Theory from First Principles","authors":"Francis Bach","year":2024,"url":"https://www.di.ens.fr/~fbach/ltfp_book.pdf","tags":["resource"]},{"id":"bach2024learning","title":"Deep Learning Theory Lecture Notes","authors":"Matus Telgarsky","year":2021,"url":"https://mjt.cs.illinois.edu/dlt/","tags":["resource"]},{"id":"kimeldorf1970correspondence","title":"A Correspondence Between Bayesian Estimation on Stochastic Processes and Smoothing by Splines","authors":"G. S. Kimeldorf and G. Wahb","venue":"The Annals of Mathematical Statistics","year":1970,"tags":["RKHS"]},{"id":"scholkopf","title":"A Generalized Representer Theorem","authors":"B. Sch\xa8olkopf, R. Herbrich, and A. J. Smola","venue":"International Conference on Computational Learning Theory","year":2001,"tags":["RKHS"]},{"id":"bach2024learning","title":"High-Dimensional Statistics: A Non-Asymptotic Viewpoint (Ch. 12)","authors":"Martin Wainwright","venue":"Cambridge University Press","year":2019,"url":"https://gw2jh3xr2c.search.serialssolutions.com/?sid=sersol&SS_jc=TC0002134402&title=High-dimensional%20statistics%20%3A%20a%20non-asymptotic%20viewpoint","tags":["RKHS"]},{"id":"jacot2020implicit","title":"Implicit Regularization of Random Feature Models","authors":"Arthur Jacot, Berfin \u015eim\u015fek, Francesco Spadaro, Cl\xe9ment Hongler, Franck Gabriel","venue":"ICML","year":2020,"url":"https://arxiv.org/abs/2002.08404","tags":["generalization"]},{"id":"jacot2020implicit","final":true,"title":"Implicit Regularization of Random Feature Models","authors":"Arthur Jacot, Berfin \u015eim\u015fek, Francesco Spadaro, Cl\xe9ment Hongler, Franck Gabriel","venue":"ICML","year":2020,"url":"https://arxiv.org/abs/2002.08404","tags":["effective regularization"]},{"id":"hastie2022surprises","title":"Surprises in High-Dimensional Ridgeless Least Squares Interpolation","authors":"Trevor Hastie, Andrea Montanari, Saharon Rosset, Ryan J. Tibshirani","venue":"Annals of Statistics","year":2022,"url":"https://arxiv.org/abs/1903.08560","tags":["effective regularization"]},{"id":"simon2023eigenlearning","title":"The Eigenlearning Framework: A Conservation Law Perspective on Kernel Regression and Wide Neural Networks","authors":"James B. Simon, Madeline Dickens, Dhruva Karkada, Michael R. DeWeese","venue":"TMLR","year":2023,"url":"https://arxiv.org/abs/2110.03922","tags":["effective regularization"]},{"id":"mei2021generalizatoin","title":"The Generalization Error of Random Features Regression: Precise Asymptotics and Double Descent Curve","authors":"Song Mei, Andrea Montanari","venue":"Communications on Pure and Applied Mathematics","year":2021,"url":"https://arxiv.org/abs/1908.05355","tags":["effective regularization"]},{"id":"bartlett2020benign","final":true,"title":"Benign Overfitting in Linear Regression","authors":"Peter L. Bartlett, Philip M. Long, G\xe1bor Lugosi, Alexander Tsigler","venue":"Proceedings of the National Academy of Sciences","year":2020,"url":"https://arxiv.org/abs/1906.11300","tags":["benign overfitting"]},{"id":"chizat2019lazy","final":true,"title":"On Lazy Training in Differentiable Programming","authors":"Lenaic Chizat, Edouard Oyallon, Francis Bach","venue":"NeurIPS","year":2019,"url":"https://arxiv.org/abs/1812.07956","tags":["infinite width"]},{"id":"matthews2018gaussian","final":true,"title":"Gaussian Process Behaviour in Wide Deep Neural Networks","authors":"Alexander G. de G. Matthews, Mark Rowland, Jiri Hron, Richard E. Turner, Zoubin Ghahramani","venue":"ICLR","year":2018,"url":"https://arxiv.org/abs/1804.11271","tags":["infinite width"]},{"id":"jacot2018neural","title":"Neural Tangent Kernel: Convergence and Generalization in Neural Networks","authors":"Arthur Jacot, Franck Gabriel, Cl\xe9ment Hongler","venue":"NeurIPS","year":2018,"url":"https://arxiv.org/abs/1806.07572","tags":["infinite width"]},{"id":"arora2019exact","title":"On Exact Computation with an Infinitely Wide Neural Net","authors":"Sanjeev Arora, Simon S. Du, Wei Hu, Zhiyuan Li, Ruslan Salakhutdinov, Ruosong Wang","venue":"NeurIPS","year":2019,"url":"https://arxiv.org/abs/1904.11955","tags":["infinite width"]},{"id":"woodworth2020kernel","final":true,"title":"Kernel and Rich Regimes in Overparametrized Models","authors":"Blake Woodworth, Suriya Gunasekar, Jason D. Lee, Edward Moroshko, Pedro Savarese, Itay Golan, Daniel Soudry, Nathan Srebro","venue":"CoLT","year":2020,"url":"https://arxiv.org/abs/2002.09277","tags":["feature learning"]},{"id":"lyu2020gradient","final":true,"title":"Gradient Descent Maximizes the Margin of Homogeneous Neural Networks","authors":"Kaifeng Lyu, Jian Li","venue":"ICLR","year":2020,"url":"https://arxiv.org/abs/1906.05890","tags":["classification"]},{"id":"bahri2024explaining","final":true,"title":"Explaining Neural Scaling Laws","authors":"Yasaman Bahri, Ethan Dyer, Jared Kaplan, Jaehoon Lee, Utkarsh Sharma","venue":"Proceedings of the National Academy of Sciences","year":2024,"url":"https://arxiv.org/abs/2102.06701","tags":["scaling laws"]},{}]')},287:function(e,t,a){},288:function(e,t,a){"use strict";a.r(t);var n=a(0),r=a.n(n),l=a(31),i=a(5),s=a(6),o=a(12),c=a(7),m=a(8),u=a(21),p=a(9),h=a(13),d=a.n(h),g=a(19),f=a(2),b=a(11),E=["inside","children"],y=["children"],v=["children","className","noMb"],w=["center","children"],x=["children","className","noMb"],N=["first","children"],k=["center","children"],A=["captionClassName","maxWidth","maxHeight","children","fluid","src"],P=["children"],T=["first","firstMd","children"],C=["children"],O=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=this.props,t=e.inside,a=e.children,n=Object(b.a)(e,E);return t||(n.target="_blank"),r.a.createElement("a",n,a)}}]),a}(r.a.Component),I=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=this.props,t=e.children,a=Object(b.a)(e,y);return r.a.createElement("h1",Object.assign({className:"mb-0 text-light font-weight-bold"},a),t)}}]),a}(r.a.Component),S=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=this.props,t=e.children,a=e.className,n=e.noMb,l=Object(b.a)(e,v),i=-1===(a=a||"").indexOf("text-")?"text-dark":"";return a=i+" text-uppercase "+a,n||(a+=" mb-5"),r.a.createElement("h2",Object.assign({className:a},l),t)}}]),a}(r.a.Component),M=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=this.props,t=e.center,a=e.children,n=Object(b.a)(e,w),l="h5 text-uppercase mb-5 text-center";return t||(l+=" text-md-left"),r.a.createElement("h2",Object.assign({className:l},n),a)}}]),a}(r.a.Component),B=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=this.props,t=e.children,a=e.className,n=e.noMb,l=Object(b.a)(e,x);return a=a||"",n||(a+=" h4 mt-5 mb-4"),r.a.createElement("h3",Object.assign({className:a},l),r.a.createElement("u",null,t))}}]),a}(r.a.Component),j=(r.a.Component,function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=this.props,t=e.center,a=e.children,n=Object(b.a)(e,k),l="h6 text-uppercase mb-3 mt-4 text-center";return t||(l+=" text-md-left"),r.a.createElement("h3",Object.assign({className:l},n),a)}}]),a}(r.a.Component)),G=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=this.props,t=e.captionClassName,a=e.maxWidth,n=e.maxHeight,l=e.children,i=e.fluid,s=(e.src,Object(b.a)(e,A));t=t||"",t+=" figure-caption pt-2";var o="figure-img rounded";return i&&(o+=" img-fluid"),r.a.createElement("figure",Object.assign({className:""},s),r.a.createElement("div",{className:"bg-white p-3"},r.a.createElement("img",{src:this.props.src,className:o,alt:l,style:{maxWidth:a,maxHeight:n}})),r.a.createElement("figcaption",{className:t},l))}}]),a}(r.a.Component),R=(r.a.Component,function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=this.props,t=e.first,a=e.firstMd,n=e.children,l=Object(b.a)(e,T),i="";return t||(i+=" border-top pt-5"),a&&(i+=" d-md-none d-block"),r.a.createElement("div",null,r.a.createElement("div",Object.assign({className:i},l)),r.a.createElement("div",{className:"mb-5"},n))}}]),a}(r.a.Component)),z=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=this.props,t=e.children,a=Object(b.a)(e,C);return t||(t="anonymous feedback form"),r.a.createElement(O,Object.assign({href:"https://forms.gle/nnh5kzGzNTfBc3e8A"},a),t)}}]),a}(r.a.Component),D=["className"],L=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=this.props,t=e.className,a=Object(b.a)(e,D),n="list-unstyled";return t&&(n+=" "+t),this.props.indent&&(n+="ml-3"),r.a.createElement("ul",Object.assign({},a,{className:n}),this.props.children)}}]),a}(r.a.Component),W=a(15),J=a(33),U=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e,t="",a=Object(W.a)(this.props.authors);try{for(a.s();!(e=a.n()).done;){if(e.value.indexOf("*")>-1){t="* "+(this.props.note||"Authors contributed equally");break}}}catch(n){a.e(n)}finally{a.f()}return r.a.createElement("li",{key:this.props.title,className:"row mb-4"},r.a.createElement("div",{className:"col-md-9"},r.a.createElement("h4",{className:"h5 font-weight-bold"},this.props.isNew?r.a.createElement("span",{className:"badge badge-danger mr-2"},"NEW"):null,r.a.createElement(O,{inside:!0,className:"link-unstyled",href:this.props.website},this.props.title),this.props.award?r.a.createElement("span",{className:"h6 pl-2 text-muted text-uppercase"},"[",this.props.award,"]"):null),r.a.createElement("div",null,r.a.createElement("ul",{className:"list-inline ml-3 mt-1"},this.props.authors.map((function(e){return J.includes(e,"Geoff Pleiss")?r.a.createElement("li",{className:"list-inline-item list-inline-item-comma",key:e},r.a.createElement("strong",null,e)):r.a.createElement("li",{className:"list-inline-item list-inline-item-comma",key:e},e)}))),t?r.a.createElement("small",{className:"ml-3 text-muted"},t):null),this.props.underSubmission?r.a.createElement("div",{className:"mt-1 ml-3 font-italic"},"\u2014 Under Submission"):this.props.techReport?r.a.createElement("div",{className:"mt-1 ml-3"},"\u2014 ",r.a.createElement("span",{className:"font-italic"},"Tech Report"),", ",this.props.year):this.props.thesis?r.a.createElement("div",{className:"mt-1 ml-3 font-italic"},"Ph.D. Thesis, ",this.props.year):r.a.createElement("div",{className:"mt-1 ml-3"},"\u2014 In ",this.props.conference,", ",this.props.year)),r.a.createElement("div",{className:"col-md-3"},r.a.createElement("ul",{className:"list-inline"},this.props.pdf?r.a.createElement("li",{className:"mb-1 list-inline-item"},r.a.createElement(O,{className:"btn btn-pdf btn-sm",role:"button",href:this.props.pdf},"PDF")):null,this.props.github?r.a.createElement("li",{className:"mb-1 list-inline-item"},r.a.createElement(O,{className:"btn btn-github btn-sm",role:"button",href:this.props.github},"Github")):null,this.props.talk?r.a.createElement("li",{className:"mb-1 list-inline-item"},r.a.createElement(O,{className:"btn btn-talk btn-sm",role:"button",href:this.props.talk},"Talk")):null)))}}]),a}(r.a.Component),H=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement("li",{key:this.props.title,className:"mb-4"},r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-md-8"},r.a.createElement("h4",{className:"h5 font-weight-bold"},r.a.createElement(O,{className:"link-unstyled",href:this.props.github},this.props.title),this.props.status?r.a.createElement("span",{className:"ml-3 badge badge-info p-2 pl-3 pr-3"},this.props.status):null),r.a.createElement("div",{className:"ml-3 font-italic"},this.props.tagline),r.a.createElement("div",{className:"ml-3 mt-1 mb-1"},r.a.createElement("small",{className:"text-muted"},"Coauthors: ",this.props.coauthors.join(", ")))),r.a.createElement("ul",{className:"list-inline col-md-4"},this.props.report?r.a.createElement("li",{className:"mb-1 list-inline-item"},r.a.createElement(O,{className:"btn btn-pdf btn-sm",role:"button",href:this.props.report},"Technical Report")):null,this.props.github?r.a.createElement("li",{className:"mb-1 list-inline-item"},r.a.createElement(O,{className:"btn btn-github btn-sm",role:"button",href:this.props.github},"Github")):null,this.props.website?r.a.createElement("li",{className:"mb-1 list-inline-item"},r.a.createElement(O,{className:"btn btn-website btn-sm",role:"button",href:this.props.website},"Website")):null)))}}]),a}(r.a.Component),F=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement("li",{key:this.props.title,className:"mb-4"},r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-md-10"},r.a.createElement("h4",{className:"h5 font-weight-bold"},r.a.createElement("span",{className:"mr-3 badge badge-info p-2 pl-3 pr-3",style:{width:"150px"}},this.props.date),r.a.createElement(O,{className:"link-unstyled",href:this.props.href},this.props.title)),r.a.createElement("div",{className:"ml-3 font-italic"},this.props.tagline)),r.a.createElement("div",{className:"col-md-2"},r.a.createElement(O,{className:"btn btn-github btn-sm",role:"button",href:this.props.href},"Video"))))}}]),a}(r.a.Component),V="\nGeoff Pleiss is an assistant professor in the Department of Statistics at the University of British Columbia,\nas well as a Canada CIFAR AI Chair affiliated with the Vector Institute.\nHe earned a Ph.D. in Computer Science from Cornell University under the supervision of Prof. Kilian Weinberger, and worked with Prof. John Cunningham at the Zuckerman Institute of Columbia University. \nGeoff\u2019s research group specializes in uncertainty quantification in machine learning,\nespecially within the contexts of decision making, optimal experimental design, and scientific discovery.\nHis most notable research contributions include work on neural network calibration, scalable Gaussian processes, and ensemble methods.\nAdditionally, Geoff has co-founded many widely-used open source software projects, including the GPyTorch, LinearOperator, and CoLA libraries.\n",_=a(17),Z=a(34),K=a.n(Z),q=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(e){var n;return Object(i.a)(this,a),(n=t.call(this,e)).toggleShortBioModal=n.toggleShortBioModal.bind(Object(o.a)(n)),n.state={items:[],shortBioModalOpen:!1,loading:!1},n}return Object(s.a)(a,[{key:"componentWillUnmount",value:function(){this.unsubscribe()}},{key:"onStatusChange",value:function(e){this.setState(e)}},{key:"toggleShortBioModal",value:function(){this.setState({shortBioModalOpen:!this.state.shortBioModalOpen})}},{key:"render",value:function(){var e=r.a.createElement("picture",{className:"d-inline-block mb-md-4 ml-md-5"},r.a.createElement("img",{className:"rounded img-thumbnail",alt:"Geoff Pleiss",src:K.a,style:{width:"100%",maxWidth:"275px"}})),t=r.a.createElement("span",null,"I am an assistant professor in the "," ",r.a.createElement(O,{className:"text-muted",href:"http://stat.ubc.ca/"},"Department of Statistics")," ","at the University of British Columbia, where I am an inaugural member of "," ",r.a.createElement(O,{className:"text-muted",href:"http://caida.ubc.ca/"},"CAIDA's")," "," ",r.a.createElement(O,{className:"text-muted",href:"http://caida.ubc.ca/aim-si"},"AIM-SI")," (AI Methods for Scientific Impact) cluster. I am also a ",r.a.createElement(O,{className:"text-muted",href:"https://cifar.ca/ai/canada-cifar-ai-chairs/"},"Canada CIFAR AI Chair")," ","and a faculty member at the "," ",r.a.createElement(O,{className:"text-muted",href:"http://vectorinstitue.ai/"},"Vector Institute"),".");return r.a.createElement("div",null,r.a.createElement("div",{className:"container py-8 pt-md-10"},r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-12 col-md-6 col-xl-8"},r.a.createElement(S,{noMb:!0,className:"text-center text-md-left"},"Geoff Pleiss"),r.a.createElement("div",{className:"col-12 d-md-none text-center my-3"},e),r.a.createElement("div",{className:"row mx-0 mb-5 text-muted font-italic text-center text-md-left"},r.a.createElement("div",{className:"col-12 col-xl-12 px-md-0 mt-3"},"Assistant Professor,"," ",r.a.createElement(O,{className:"text-muted",href:"http://stat.ubc.ca/"},"UBC Department of Statistics"),r.a.createElement("br",null),"CIFAR AI Chair,"," ",r.a.createElement(O,{className:"text-muted",href:"http://vectorinstitute.ai/"},"Vector Institute"),r.a.createElement("br",null),r.a.createElement(d.a,{icon:_.a,size:"1x",title:"Email: ",className:"mr-3"}),"geoff.pleiss <at> stat.ubc.ca")),r.a.createElement("p",{className:"d-none d-xl-block","aria-hidden":"true"},t)),r.a.createElement("div",{className:"col-md-6 col-xl-4 d-none d-md-block text-md-right","aria-hidden":"true"},e)),r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-sm-12"},r.a.createElement("p",{className:"d-xl-none"},t),r.a.createElement("p",null,"My research interests intersect deep learning and probablistic modeling. More specifically, I'm interested in heuristic and approximate notions of uncertainty from machine learning models, and how they can inform reliable and optimal downstream decisions within the contexts of experimental design and scientific discovery. Major focuses of my work include:"),r.a.createElement("ol",null,r.a.createElement("li",null,"neural network uncertainty quantification,"),r.a.createElement("li",null,"Bayesian optimization,"),r.a.createElement("li",null,"Gaussian processes, and"),r.a.createElement("li",null,"ensemble methods.")),r.a.createElement("p",null,"I am also an active open source contributior. Most notably, I co-created and maintain the ",r.a.createElement(O,{href:"http://gpytorch.ai"},"GPyTorch")," Gaussian process library with ",r.a.createElement(O,{href:"https://jacobrgardner.github.io/"},"Jake Gardner"),"."),r.a.createElement("p",null,"Previously, I was a postdoc at Columbia University with ",r.a.createElement(O,{href:"https://stat.columbia.edu/~cunningham/"},"John P. Cunningham"),". I received my Ph.D. from the CS department at Cornell University in 2020 where I was advised by ",r.a.createElement(O,{href:"http://kilian.cs.cornell.edu/"},"Kilian Weinberger")," and also worked closely with ",r.a.createElement(O,{href:"https://cims.nyu.edu/~andrewgw/"},"Andrew Gordon Wilson"),".")),r.a.createElement("div",{className:"col-md-12"},r.a.createElement("ul",{className:"list-inline mt-2"},r.a.createElement("li",{className:"list-inline-item mt-2"},r.a.createElement(O,{className:"btn btn-light",role:"button",href:"/geoffpleiss_cv.pdf"},"CV")),r.a.createElement("li",{className:"list-inline-item mt-2"},r.a.createElement("button",{className:"btn btn-light",onClick:this.toggleShortBioModal},"Short Bio")),r.a.createElement("li",{className:"list-inline-item mt-2"},r.a.createElement(O,{className:"btn btn-light",role:"button",href:"/geoffpleiss_research_statement.pdf"},"Research Statement")),r.a.createElement("li",{className:"list-inline-item mt-2"},r.a.createElement(O,{className:"btn btn-light",role:"button",href:"/geoffpleiss_teaching_statement.pdf"},"Teaching Statement")),r.a.createElement("li",{className:"list-inline-item mt-2"},r.a.createElement(O,{className:"btn btn-light",role:"button",href:"/geoffpleiss_dei_statement.pdf"},"DEI Statement"))),r.a.createElement(f.e,{size:"lg",isOpen:this.state.shortBioModalOpen,toggle:this.toggleShortBioModal},r.a.createElement(f.g,{className:"ml-3 mr-3",toggle:this.toggleShortBioModal},"Short Bio"),r.a.createElement(f.f,null,r.a.createElement("p",{className:"m-3"},V))))),r.a.createElement("div",{className:"clearfix"}),r.a.createElement("hr",{className:"mt-4 mb-5"}),r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-sm-12"},r.a.createElement("p",null,r.a.createElement("strong",null,"Interested in joining my lab?")," I am looking for prospective M.S. students, Ph.D students, and postdocs with research interests similar to my own. While I am open to strong students with any ML/stats interests, I am particularly hoping to hire lab members interested in theoretical or applied work on Bayesian optimization or neural network uncertainty quantification."),r.a.createElement("p",null,"See the ",r.a.createElement(O,{inside:!0,href:"/prospective_member.html"},"page on joining my lab")," for information on how to apply/contact me.")))),r.a.createElement("section",{className:"pt-10 pb-8 bg-light"},r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"row pt-4 pb-8"},r.a.createElement("div",{className:"col-md-12"},r.a.createElement(S,{className:"mb-1",noMb:!0},"Recent and Selected Publications"),r.a.createElement("p",{className:"mb-5"},r.a.createElement("small",{className:"font-italic"},"For a full list of publications, please see my ",r.a.createElement(O,{href:"/geoffpleiss_cv.pdf"},"CV")," or my ",r.a.createElement(O,{href:"https://scholar.google.com/citations?user=XO8T-Y4AAAAJ&hl=en&oi=ao"},"Google Scholar")," page.")),r.a.createElement(L,{className:"list-unstyled"},r.a.createElement(U,{title:"Theoretical Limitations of Ensembles in the Age of Overparameterization",authors:["Niclas Dern","John P. Cunningham","Geoff Pleiss"],arxiv:"https://arxiv.org/abs/2410.16201",pdf:"https://arxiv.org/pdf/2410.16201.pdf",github:"https://github.com/nic-dern/theoretical-limitations-overparameterized-ensembles",underSubmission:!0,isNew:!0,year:"2024"}),r.a.createElement(U,{title:"Approximation-Aware Bayesian Optimization",authors:["Natalie Maus","Kyurae Kim","Geoff Pleiss","David Eriksson","John P. Cunningham","Jacob R. Gardner"],isNew:!0,arxiv:"https://arxiv.org/abs/2406.04308",pdf:"https://arxiv.org/pdf/2406.04308.pdf",github:"https://github.com/nataliemaus/improvement-vi",conference:"NeurIPS",year:"2024"}),r.a.createElement(U,{title:"Computation-Aware Gaussian Processes: Model Selection And Linear-Time Inference",authors:["Jonathan Wenger","Kaiwen Wu","Philipp Hennig","Jacob R. Gardner","Geoff Pleiss","John P. Cunningham"],isNew:!0,arxiv:"https://arxiv.org/abs/2411.01036",pdf:"https://arxiv.org/pdf/2411.01036.pdf",github:"https://github.com/cornellius-gp/gpytorch/blob/e0e8cd5365e7eea72befaa02d644f588984fd337/gpytorch/models/computation_aware_gp.py",conference:"NeurIPS",year:"2024"}),r.a.createElement(U,{title:"A Sober Look at LLMs for Material Discovery: Are They Actually Good for Bayesian Optimization Over Molecules?",authors:["Agustinus Kristiadi","Felix Strieth-Kalthoff","Marta Skreta","Pascal Poupart","Al\xe1n Aspuru-Guzik","Geoff Pleiss"],arxiv:"https://arxiv.org/abs/2402.05015",pdf:"https://arxiv.org/pdf/2402.05015.pdf",github:"https://github.com/wiseodd/lapeft-bayesopt",conference:"ICML",year:"2024"}),r.a.createElement(U,{title:"Pathologies of Predictive Diversity in Deep Ensembles",authors:["Taiga Abe","E. Kelly Buchanan","Geoff Pleiss","John P. Cunningham"],award:"featured paper",arxiv:"https://arxiv.org/abs/2302.00704",pdf:"https://arxiv.org/pdf/2302.00704.pdf",talk:"https://www.youtube.com/watch?v=LINT01z05Bs",conference:"TMLR",year:"2024"}),r.a.createElement(U,{title:"Posterior and Computational Uncertainty in Gaussian Processes",authors:["Jonathan Wenger","Geoff Pleiss","Marvin Pf\xf6rtner","Philipp Hennig","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2205.15449",pdf:"https://arxiv.org/pdf/2205.15449.pdf",github:"https://github.com/JonathanWenger/itergp",conference:"NeurIPS",year:"2022"}),r.a.createElement(U,{title:"Deep Ensembles Work, But Are They Necessary?",authors:["Taiga Abe*","E. Kelly Buchanan*","Geoff Pleiss","Richard Zemel","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2202.06985",pdf:"https://arxiv.org/pdf/2202.06985.pdf",github:"https://github.com/cellistigs/interp_ensembles",talk:"https://www.youtube.com/watch?v=703FzYv-j9o&ab_channel=VectorInstitute",conference:"NeurIPS",year:"2022"}),r.a.createElement(U,{title:"The Limitations of Large Width in Neural Networks: A Deep Gaussian Process Perspective",authors:["Geoff Pleiss","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2106.06529",pdf:"https://arxiv.org/pdf/2106.06529.pdf",conference:"NeurIPS",github:"https://github.com/gpleiss/limits_of_large_width",talk:"https://slideslive.com/38967621/the-limitations-of-large-width-in-neural-networks-a-deep-gaussian-process-perspective?ref=search-presentations-geoff+pleiss",year:"2021"}),r.a.createElement(U,{title:"GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration",authors:["Jacob R. Gardner*","Geoff Pleiss*","David Bindel","Kilian Q. Weinberger","Andrew Gordon Wilson"],arxiv:"https://arxiv.org/abs/1809.11165",pdf:"https://arxiv.org/pdf/1809.11165.pdf",award:"spotlight",conference:"NeurIPS",year:"2018",talk:"https://www.videoken.com/embed/QcFGBPNh24E?tocitem=101",github:"https://github.com/cornellius-gp/gpytorch"}),r.a.createElement(U,{title:"On Fairness and Calibration",authors:["Geoff Pleiss*","Manish Raghavan*","Felix Wu","Jon Kleinberg","Kilian Q. Weinberger"],conference:"NeurIPS",year:"2017",arxiv:"https://arxiv.org/abs/1709.02012",pdf:"https://arxiv.org/pdf/1709.02012.pdf",github:"https://github.com/gpleiss/equalized_odds_and_calibration"}),r.a.createElement(U,{title:"On Calibration of Modern Neural Networks",authors:["Chuan Gao*","Geoff Pleiss*","Yu Sun*","Kilian Q. Weinberger"],conference:"ICML",year:"2017",website:"/blog/nn_calibration.html",arxiv:"https://arxiv.org/abs/1706.04599",pdf:"https://arxiv.org/pdf/1706.04599.pdf",github:"https://github.com/gpleiss/temperature_scaling",talk:"https://vimeo.com/238242536"})))))),r.a.createElement("section",{className:"pt-8 pb-5 bg-medium text-light"},r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-md-12"},r.a.createElement(S,{className:"mb-1 text-light",noMb:!0},"Recent and Selected Talks"),r.a.createElement("div",{className:"mb-5"}),r.a.createElement(L,null,r.a.createElement(F,{title:"Ensembles in the Age of Overparameterization: Promises and Pathologies",tagline:"Recent empirical and theoretical work characterizing ensembles of neural networks.",date:"Oct. 2024",href:"https://www.youtube.com/watch?v=LINT01z05Bs"}),r.a.createElement(F,{title:"Troubling Trajectories for Uncertainty Quantification and Decision Making with Neural Networks",tagline:"A discussion of uncertainty quantification and my recent work on neural network ensembles.",date:"Dec. 2023",href:"https://www.youtube.com/watch?v=703FzYv-j9o&ab_channel=VectorInstitute"}),r.a.createElement(F,{title:"Bridging The Gap Between Deep Learning and Probabilistic Modeling",tagline:"A talk connecting my Gaussian process and neural network research.",date:"Spring 2022",href:"https://www.youtube.com/watch?v=TUV4oEY33pE&ab_channel=CUEngineeringAcademics"})))))),r.a.createElement("section",{className:"pt-8 pb-5 bg-dark text-light"},r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-md-12"},r.a.createElement(S,{className:"mb-1 text-light",noMb:!0},"Selected Open Source"),r.a.createElement("p",{className:"mb-5"},r.a.createElement("small",{className:"font-italic"},"For a full list of respositories I actively contribute to, please see my ",r.a.createElement(O,{href:"https://github.com/gpleiss"},"Github")," page.")),r.a.createElement(L,null,r.a.createElement(H,{title:"GPyTorch",status:"v1.13 Release",coauthors:["Jacob R. Gardner"],tagline:"A implementation of Gaussian processes in PyTorch, designed for speed, modularity, and prototyping.",website:"https://gpytorch.ai",github:"https://github.com/cornellius-gp/GPyTorch"}),r.a.createElement(H,{title:"CoLA (Compositional Linear Algebra)",status:"Beta Release",coauthors:["Andres Potapczynski","Marc Anton Finzi"],tagline:"A library for structured linear algebra operations in JaX and PyTorch.",website:"https://cola.readthedocs.io/",github:"https://github.com/wilson-labs/cola"})))))))}}]),a}(r.a.Component),Y=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement("div",null,r.a.createElement("div",{className:"container py-8 pt-md-10"},r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-12"},r.a.createElement("section",null,r.a.createElement(S,null,"How to Apply"),r.a.createElement("dl",{className:"row"},r.a.createElement("dt",{className:"col-lg-3"},"Prospective MSc/PhD students:"),r.a.createElement("dd",{className:"col-lg-9"},r.a.createElement("p",null,"Applications go through the ",r.a.createElement(O,{href:"https://www.stat.ubc.ca/graduate-admissions"},"UBC stats department"),". Mention me as a potential advisor."),r.a.createElement("p",null,"You can also apply to the ",r.a.createElement(O,{href:"https://www.cs.ubc.ca/students/grad/admissions"},"UBC CS department")," if you would prefer to take CS courses/fulfil CS degree requirements. (I will also have the ability to be the primary advisor for CS students.) Again, mention me as a potential advisor.")),r.a.createElement("dt",{className:"col-lg-3 mt-3"},"Prospective postdocs:"),r.a.createElement("dd",{className:"col-lg-9 mt-lg-3"},"Applications go through ",r.a.createElement(O,{href:"https://vectorinstitute.bamboohr.com/jobs/view.php?id=136"},"Vector's post-doctoral fellowship.")," Mention me as a potential advisor."))),r.a.createElement("section",{className:"mt-5"},r.a.createElement(S,null,"Should I Contact You?"),r.a.createElement("p",null,"You may email me directly to start a conversation and let me know that you are interested. However, I will only respond if I think you are a good candidate, so you'll need to give me enough information to work with."),r.a.createElement("p",null,"Tell me about your prior research experience and your current research interests. Most importantly, ",r.a.createElement("em",null,"please let me know why you want to specificity work with me"),'. I prefer substance over flattery. If you say "I wish to join your esteemed lab to work on important problems in machine learning," then I will likely not respond. If you say "I am interested in uncertainty quantification for neural networks. I admire your recent studies of ensemble methods, and I have a few follow up research ideas..." then I\'ll be interested in following up with you!'),r.a.createElement("p",null,'You should include "[Potential Pleiss lab member]" in your email subject. (That will let me know that you\'ve read the information on this page!)')),r.a.createElement("section",{className:"mt-5"},r.a.createElement(S,null,"Are There Internship, Undergraduate, or Visiting Student Opportunities?"),r.a.createElement("p",null,"I will likely hire undergraduates directly through UBC's internal programs. Look out for postings this winter. It doesn't hurt to contact me about other opportunities, but again I won't respond unless you pique my interest."))))))}}]),a}(r.a.Component),Q=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement("div",null,r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-sm-12"},r.a.createElement(R,null,"Page not found.")))))}}]),a}(r.a.Component),X=a(35),$=a.n(X),ee=a(16),te=a.n(ee),ae=["className","children"],ne=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"componentDidMount",value:function(){this.highlightCode()}},{key:"componentDidUpdate",value:function(){this.highlightCode()}},{key:"highlightCode",value:function(){var e,t=te.a.findDOMNode(this).querySelectorAll("pre code");for(e=0;e<t.length;e++)$.a.highlightBlock(t[e])}},{key:"render",value:function(){var e=this.props,t=e.className,a=e.children,n=Object(b.a)(e,ae);return r.a.createElement("pre",n,r.a.createElement("code",{className:t},a))}}]),a}(r.a.Component),re=a(36),le=a.n(re),ie=(a(286),["children","inline"]),se=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(e){var n;return Object(i.a)(this,a),(n=t.call(this,e)).state={katexHtml:void 0,error:void 0},n}return Object(s.a)(a,[{key:"componentDidMount",value:function(){this.updateHtml()}},{key:"componentWillReceiveProps",value:function(e){this.props.children!==e.children&&this.updateHtml()}},{key:"updateHtml",value:function(){try{var e=le.a.renderToString(this.props.children,{displayMode:!this.props.inline});this.setState({katexHtml:e,error:void 0})}catch(t){this.setState({katexHtml:void 0,error:t})}}},{key:"render",value:function(){var e=this.props,t=(e.children,e.inline),a=Object(b.a)(e,ie);if(this.state.katexHtml)return t?r.a.createElement("span",Object.assign({},a,{dangerouslySetInnerHTML:{__html:this.state.katexHtml}})):r.a.createElement("div",Object.assign({},a,{dangerouslySetInnerHTML:{__html:this.state.katexHtml}}));if(this.state.error)throw this.state.error;return t?r.a.createElement("span",null,"..."):r.a.createElement("div",null,"...")}}]),a}(r.a.Component),oe=a(37),ce=a.n(oe),me=a(38),ue=a.n(me),pe=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(e){var n;return Object(i.a)(this,a),(n=t.call(this,e)).toggleNiculescuTooltip=n.toggleNiculescuTooltip.bind(Object(o.a)(n)),n.toggleBibtexModal=n.toggleBibtexModal.bind(Object(o.a)(n)),n.state={items:[],niculescuTooltipOpen:!1,bibtexModalOpen:!1,loading:!1},n}return Object(s.a)(a,[{key:"componentWillUnmount",value:function(){this.unsubscribe()}},{key:"onStatusChange",value:function(e){this.setState(e)}},{key:"toggleNiculescuTooltip",value:function(){this.setState({niculescuTooltipOpen:!this.state.niculescuTooltipOpen})}},{key:"toggleBibtexModal",value:function(){this.setState({bibtexModalOpen:!this.state.bibtexModalOpen})}},{key:"render",value:function(){return r.a.createElement("div",null,r.a.createElement("div",{className:"bg-gradient-primary pt-10 pb-5 shadow-bottom"},r.a.createElement("div",{className:"container text-center"},r.a.createElement(I,null,"Calibrating Neural Networks"))),r.a.createElement("div",{className:"bg-gradient-light pt-5 pb-4 shadow-bottom",id:"reliability-diagrams"},r.a.createElement("div",{className:"container text-center"},r.a.createElement("div",{className:"row text-center"},r.a.createElement("div",{className:"col-12 offset-lg-1 col-lg-5 mb-2 mb-lg-0"},r.a.createElement(G,{src:ce.a,maxWidth:"300px",maxHeight:"300px"},"An uncalibrated neural network, before temperature scaling. The reliability diagram indicates miscalibration.")),r.a.createElement("div",{className:"col-12 col-lg-5 mb-0"},r.a.createElement(G,{src:ue.a,maxWidth:"300px",maxHeight:"300px"},"Neural network after temperature scaling. The reliability diagram indicates a well-calibrated network."))))),r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"row mt-5"},r.a.createElement("div",{className:"col-12 col-md-3 order-12"},r.a.createElement("div",{className:"pl-4 pr-4"},r.a.createElement(R,{firstMd:!0},r.a.createElement(M,{center:!0},"Quick Links"),r.a.createElement("nav",{className:"nav flex-column text-center"},r.a.createElement(O,{className:"nav-link mt-0 pt-0 text-truncate",href:"https://arxiv.org/abs/1706.04599"},r.a.createElement(d.a,{icon:_.b}),r.a.createElement("span",{className:"d-inline-block pl-2"},"Publication")),r.a.createElement(O,{className:"nav-link text-truncate",href:"https://github.com/gpleiss/temperature_scaling"},r.a.createElement(d.a,{icon:g.a}),r.a.createElement("span",{className:"d-inline-block pl-2"},"Code")),r.a.createElement(O,{className:"nav-link text-truncate",href:"https://vimeo.com/238242536"},r.a.createElement(d.a,{icon:_.c}),r.a.createElement("span",{className:"d-inline-block pl-2"},"Video")))),r.a.createElement(R,null,r.a.createElement(M,{center:!0},"Authors"),r.a.createElement("ul",{className:"list-unstyled text-center text-dark"},r.a.createElement("li",null,r.a.createElement(O,{href:"https://scholar.google.com/citations?user=0gp5M-kAAAAJ&hl=en"},"Chuan Guo")),r.a.createElement("li",{className:"pt-2"},r.a.createElement(O,{inside:!0,href:"/"},"Geoff Pleiss")),r.a.createElement("li",{className:"pt-2"},r.a.createElement(O,{href:"https://scholar.google.com/citations?user=a7drwRMAAAAJ&hl=en"},"Yu Sun")),r.a.createElement("li",{className:"pt-2"},r.a.createElement(O,{href:"https://www.cs.cornell.edu/~kilian/"},"Kilian Weinberger")))))),r.a.createElement("div",{className:"col-12 order-1 col-md-9"},r.a.createElement(R,{first:!0},r.a.createElement(M,null,"Motivation"),r.a.createElement("p",null,'Neural networks output "confidence" scores along with predictions in classification. Ideally, these confidence scores should match the true correctness likelihood. For example, if we assign 80% confidence to 100 predictions, then we\'d expect that 80% of the predictions are actually correct. If this is the case, we say the network is ',r.a.createElement("strong",null,"calibrated"),". Modern neural networks tend to be very poorly calibrated. We find that this is a result of recent architectural trends, such as increased network capacity and less regularization."),r.a.createElement("p",null,"There is a surprisingly simple recipe to fix this problem: ",r.a.createElement("strong",null,"Temperature Scaling")," is a post-processing technique which can almost perfectly restore network calibration.  ",r.a.createElement("em",null,"It requires no additional training data, takes a millisecond to perform, and can be implemented in 2 lines of code.")),r.a.createElement("p",null,"A simple way to visualize calibration is plotting accuracy as a function of confidence (known as a ",r.a.createElement("strong",null,r.a.createElement("a",{href:"http://www.datascienceassn.org/sites/default/files/Predicting%20good%20probabilities%20with%20supervised%20learning.pdf",id:"cite-niculescu2005predicting"},"reliability diagram")),"). Since confidence should reflect accuracy, we'd like for the plot to be an identity function. In the ",r.a.createElement(O,{inside:!0,href:"#reliability-diagrams"},"reliability diagram above")," on the left, we see that a DenseNet trained on CIFAR-100 is extremely overconfident. However, after applying temperature scaling, the network becomes very well calibrated."),r.a.createElement(f.o,{placement:"bottom",isOpen:this.state.niculescuTooltipOpen,target:"cite-niculescu2005predicting",toggle:this.toggleNiculescuTooltip},"Niculescu-Mizil, A., & Caruana, R. ",r.a.createElement("strong",null,"Predicting good probabilities with supervised learning"),". In ",r.a.createElement("em",null,"ICML"),", 2005.")),r.a.createElement(R,{id:"temperature-scaling"},r.a.createElement(M,null,"What is Temperature Scaling?"),r.a.createElement("p",null,"For classification problems, the neural network output a vector known as the ",r.a.createElement("strong",null,"logits"),". The logits vector is passed through a softmax function to get class probabilities. Temperature scaling simply divides the logits vector by a learned scalar parameter, i.e."),r.a.createElement("div",{className:"text-center bg-light border-rounded p-1 mb-3 mt-3"},r.a.createElement(se,null,"P( \\hat \\mathbf y ) = \\frac{e^{\\mathbf z / T}}{\\sum_j e^{z_j / T}}")),r.a.createElement("p",null,"where ",r.a.createElement(se,{inline:!0},"\\hat y")," is the prediction, where ",r.a.createElement(se,{inline:!0},"\\mathbf z")," is the logit, and ",r.a.createElement(se,{inline:!0},"T")," is the learned parameter. We learn this parameter on a validation set, where ",r.a.createElement(se,{inline:!0},"T")," is chosen to minimize negative log likelihood. Intuitively, temperature scaling simply softens the neural network outputs. This makes the network slightly less confident, which makes the confidence scores reflect true probabilities.")),r.a.createElement(R,null,r.a.createElement(M,null,"References"),r.a.createElement("p",null,"This work is introduced in:"),r.a.createElement("blockquote",{className:"text-center mt-2 mb-3"},"Guo, C., Pleiss, G., Sun, Y. and Weinberger, K.Q.  ",r.a.createElement("strong",null,"On Calibration of Modern Neural Networks"),". In ",r.a.createElement("em",null,"ICML"),", 2017."),r.a.createElement("ul",null,r.a.createElement("li",null,r.a.createElement(O,{href:"https://arxiv.org/abs/1706.04599"},"Paper on ArXiV")),r.a.createElement("li",null,r.a.createElement("button",{className:"btn btn-link p-0",type:"button",onClick:this.toggleBibtexModal},"BibTeX")),r.a.createElement("li",null,r.a.createElement(O,{href:"https://vimeo.com/238242536"},"Video of ICML talk"))),r.a.createElement(f.e,{size:"lg",isOpen:this.state.bibtexModalOpen,toggle:this.toggleBibtexModal},r.a.createElement(f.g,{toggle:this.toggleBibtexModal},"BibTeX"),r.a.createElement(f.f,null,r.a.createElement("pre",null,"\n@inproceedings{guo2017calibration,\n  title={On calibration of modern neural networks},\n  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},\n  journal={ICML},\n  year={2017}\n}\t\n\t\t\t\t\t\t\t\t\t\t")))),r.a.createElement(R,null,r.a.createElement(M,null,"Code"),r.a.createElement("p",null,"Temperature scaling can be added incredibly easily to any model. In PyTorch for example, add the following to a model after training:"),r.a.createElement(ne,{className:"python shadow-subtle pl-4 pr-4 pt-0 pb-0 mb-3 mt-3"},"\nclass Model(torch.nn.Module):\n    def __init__(self):\n        # ...\n        self.temperature = torch.nn.Parameter(torch.ones(1))\n\n    def forward(self, x):\n        # ...\n        # logits = final output of neural network\n        return logits / self.temperature\n                "),r.a.createElement("p",null,"Then simply optimize the ",r.a.createElement("code",null,"self.temperature")," parameter with a few iterations of gradient descent. For a more complete example, check out this ",r.a.createElement(O,{href:"https://github.com/gpleiss/temperature_scaling"},"PyTorch temperature scaling example on Github"),".")),r.a.createElement(R,null,r.a.createElement(M,null,"FAQ"),r.a.createElement("p",{className:"mb-1"},r.a.createElement("strong",null,"Does temperature scaling work for regression?")),r.a.createElement("p",{className:"ml-4"},"Temperature scaling only works for classification. On regression probles, networks tend to output only point predictions, so there is no measure of uncertainty to calibrate."),r.a.createElement("p",{className:"mb-1"},r.a.createElement("strong",null,"Can temperature scaling be used to detect adversarial examples?")),r.a.createElement("p",{className:"ml-4"},"Temperature scaling works when the test distribution is the same as the training distribution. Since adversarial examples don't belong to the training distribution, temperature scaling is not guarenteed to produce a calibrated probability on these samples."),r.a.createElement("p",{className:"mb-1"},r.a.createElement("strong",null,"Why is temperature scaling a post-processing step? Can you find the temperature during training?")),r.a.createElement("p",{className:"ml-4"},"The temperature parameter can't be adjusted at training time. The network would simply learn to make the temperature as low as possible, so that it can be very confident on the training examples. (This is why miscalibration occurs in the first place.)"))))))}}]),a}(r.a.Component),he=a(39),de=a.n(he),ge=a(40),fe=a.n(ge),be=a(41),Ee=a.n(be),ye=a(42),ve=a.n(ye),we=a(43),xe=a.n(we),Ne=a(44),ke=a.n(Ne),Ae=a(45),Pe=a.n(Ae),Te=a(46),Ce=a.n(Te),Oe=a(47),Ie=a.n(Oe),Se=a(48),Me=a.n(Se),Be=a(49),je=a.n(Be),Ge=a(50),Re=a.n(Ge),ze=a(51),De=a.n(ze),Le=a(52),We=a.n(Le),Je=a(53),Ue=a.n(Je),He=a(54),Fe=a.n(He),Ve=a(55),_e=a.n(Ve),Ze=a(56),Ke=a.n(Ze),qe=a(57),Ye=a.n(qe),Qe=a(58),Xe=a.n(Qe),$e=a(59),et=a.n($e),tt=a(60),at=a.n(tt),nt=a(61),rt=a.n(nt),lt=a(62),it=a.n(lt),st=a(63),ot=a.n(st),ct=a(64),mt=a.n(ct),ut=a(65),pt=a.n(ut),ht=a(66),dt=a.n(ht),gt=a(67),ft=a.n(gt),bt=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(e){var n;return Object(i.a)(this,a),(n=t.call(this,e)).toggleTeaserTooltip=n.toggleTeaserTooltip.bind(Object(o.a)(n)),n.toggleMarginTooltip=n.toggleMarginTooltip.bind(Object(o.a)(n)),n.toggleBibtexModal=n.toggleBibtexModal.bind(Object(o.a)(n)),n.state={items:[],teaserTooltipOpen:!1,marginTooltipOpen:!1,modalOpen:!1,loading:!1},n}return Object(s.a)(a,[{key:"componentWillUnmount",value:function(){this.unsubscribe()}},{key:"onStatusChange",value:function(e){this.setState(e)}},{key:"toggleTeaserTooltip",value:function(){this.setState({teaserTooltipOpen:!this.state.teaserTooltipOpen})}},{key:"toggleMarginTooltip",value:function(){this.setState({marginTooltipOpen:!this.state.marginTooltipOpen})}},{key:"toggleBibtexModal",value:function(){this.setState({bibtexModalOpen:!this.state.bibtexModalOpen})}},{key:"render",value:function(){return r.a.createElement("div",null,r.a.createElement("div",{className:"bg-gradient-primary pt-10 pb-5 shadow-bottom"},r.a.createElement("div",{className:"container text-center"},r.a.createElement(I,null,"The Area Under the Margin (AUM) Statistic"))),r.a.createElement("div",{className:"bg-gradient-light pt-5 pb-4 shadow-bottom"},r.a.createElement("div",{className:"container text-center"},r.a.createElement("div",{className:"row text-center"},r.a.createElement("div",{className:"col-12 offset-lg-1 col-lg-5 mb-2 mb-lg-0"},r.a.createElement(G,{src:de.a,fluid:!0,maxHeight:"300px"},'Logits for a correctly-labeled CIFAR10 example. The "dog" logit grows much faster than all others, resulting in a large positive margin and AUM (green area).')),r.a.createElement("div",{className:"col-12 col-lg-5 mb-0"},r.a.createElement(G,{src:fe.a,fluid:!0,maxHeight:"300px"},'Logits for a mislabeled CIFAR10 example. The "dog" logit grows slower than the (unobserved) true class logit, resulting in a negative margin and AUM (red area).'))))),r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"row mt-5"},r.a.createElement("div",{className:"col-12 col-md-3 order-12"},r.a.createElement("div",{className:"pl-4 pr-4"},r.a.createElement(R,{firstMd:!0},r.a.createElement(M,{center:!0},"Quick Links"),r.a.createElement("nav",{className:"nav flex-column text-center"},r.a.createElement(O,{className:"nav-link mt-0 pt-0 text-truncate",href:"https://arxiv.org/abs/2001.10528"},r.a.createElement(d.a,{icon:_.b}),r.a.createElement("span",{className:"d-inline-block pl-2"},"Publication")),r.a.createElement(O,{className:"nav-link text-truncate",href:"https://github.com/asappresearch/aum"},r.a.createElement(d.a,{icon:g.a}),r.a.createElement("span",{className:"d-inline-block pl-2"},"Code")))),r.a.createElement(R,null,r.a.createElement(M,{center:!0},"Authors"),r.a.createElement("ul",{className:"list-unstyled text-center text-dark"},r.a.createElement("li",{className:"pt-2"},r.a.createElement(O,{inside:!0,href:"/"},"Geoff Pleiss")),r.a.createElement("li",{className:"pt-2"},r.a.createElement(O,{href:"https://tiiiger.github.io/"},"Tianyi Zhang")),r.a.createElement("li",{className:"pt-2"},r.a.createElement(O,{href:"http://eelenberg.github.io/"},"Ethan R. Elenberg")),r.a.createElement("li",{className:"pt-2"},r.a.createElement(O,{href:"https://www.cs.cornell.edu/~kilian/"},"Kilian Weinberger")))))),r.a.createElement("div",{className:"col-12 order-1 col-md-9"},r.a.createElement(R,{first:!0},r.a.createElement(M,null,"Motivation"),r.a.createElement("p",null,"Even the most high-power neural network architectures will be prone to error if trained on ",r.a.createElement("strong",null,"mislabeled or highly-ambiguous data"),'. Some datasets\u2014especially those that are "weakly-labeled" or annotated by vendor services\u2014are succeptible to such examples. Even some of the most commonly-used datasets, like MNIST and ImageNet, contain several mislabeled examples:'),r.a.createElement("div",{className:"text-center"},r.a.createElement("figure",{id:"example-mislabeled"},r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-md-4 col-12 d-inline-block align-middle"},r.a.createElement("img",{src:Ee.a,className:"figure-img round fluid",alt:"Mislabeled MNIST Samples",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-2 col-6"},r.a.createElement("img",{src:ve.a,className:"figure-img round fluid",alt:"Mislabeled ImageNet Sample: Beaver",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-2 col-6"},r.a.createElement("img",{src:xe.a,className:"figure-img round fluid",alt:"Mislabeled ImageNet Sample: Mushroom",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-2 col-6"},r.a.createElement("img",{src:ke.a,className:"figure-img round fluid",alt:"Mislabeled ImageNet Sample: Sock",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-2 col-6"},r.a.createElement("img",{src:Pe.a,className:"figure-img round fluid",alt:"Mislabeled ImageNet Sample: Lionfish",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}}))),r.a.createElement("figcaption",{className:"figure-caption pt-2"},"Mislabeled training examples from MNIST and ImageNet. These examples were automatically identified using the AUM statistic."))),r.a.createElement("p",null,"Modern neural networks have sufficient capacity to memorize these mislabeled examples. This memorization will hurt generalization, and thus is a bottleneck limiting the performance of these models. To combat this, we wish to ",r.a.createElement("strong",null,"identify and remove samples")," that are ",r.a.createElement("em",null,"mislabeled, highly-ambigouous, or otherwise harmful to generalization.")),r.a.createElement("p",null)),r.a.createElement(R,{id:"aum"},r.a.createElement(M,null,"The Area Under the Margin (AUM) Statistic"),r.a.createElement("p",null,"Mislabeled samples hurt network generalization, while clean samples help generalization. One simple metric that ",r.a.createElement(O,{id:"margin-paper",href:"https://arxiv.org/abs/1810.00113"},"has been shown to be strongly correlated with neural network generalization")," is the ",r.a.createElement("strong",null,"margin"),". At epoch ",r.a.createElement(se,{inline:!0},"t"),", the margin of sample ",r.a.createElement(se,{inline:!0},"(\\mathbf x, y)")," is defined as:"),r.a.createElement(f.o,{placement:"bottom",isOpen:this.state.marginTooltipOpen,target:"margin-paper",toggle:this.toggleMarginTooltip},"E.g. Jiang, Y., Krishnan, D., Mobahi, H. and Bengio, S., 2018. ",r.a.createElement("strong",null,"Predicting the generalization gap in deep networks with margin distributions.")," In ",r.a.createElement("em",null,"ICLR"),", 2019."),r.a.createElement("div",{className:"text-center bg-light border-rounded p-1 mb-3 mt-3"},r.a.createElement(se,null,"M^{(t)} (\\mathbf x, y) = z_y^{(t)}(\\mathbf x) - \\max_{i \\ne y} z_i^{(t)}(\\mathbf x)"),r.a.createElement("small",null,r.a.createElement(se,{inline:!0},"(z_i^{(t)}(\\mathbf x)")," is the model's logit\u2014pre-softmax output\u2014corresponding to class ",r.a.createElement(se,{inline:!0},"i"),".)")),r.a.createElement("p",null,"Intuitively, the margin for any given sample is affected by two forces."),r.a.createElement("ol",null,r.a.createElement("li",null,"its own gradient updates; and"),r.a.createElement("li",null,"gradient updates from similar (generalizable) samples.")),r.a.createElement("p",null,"If a sample is correctly labeled, these two forces amplify one another to improve the margin. However, these forces are opposed for mislabeled samples. The first force increases the (incorrect) assigned logit while the second force increases the (hidden) ground-truth logit."),r.a.createElement("p",null,"We therefore expect that\u2014",r.a.createElement("strong",null,"on average"),"\u2014a mislabeled sample has a lower margin than a correctly-labeled sample. We capture this by averaging the margin for a given sample over all ",r.a.createElement(se,{inline:!0},"T")," training epochs:"),r.a.createElement("div",{className:"text-center bg-light border-rounded p-1 mb-3 mt-3"},r.a.createElement(se,null,"\\text{AUM} (\\mathbf x, y) = \\frac 1 T \\sum_{t=1}^T M^{(t)} (\\mathbf x, y)")),r.a.createElement("p",null,"This statistic is referred to as the Area Under the Margin, or AUM. It is illustrated in ",r.a.createElement(O,{inside:!0,href:"#aum-teaser",id:"teaser-info"},"plots above"),", which plots the logits over time for two training samples. The correctly-labeled sample have large margins, corresponding to a large AUM (green region). The mislabeled sample has a negative margin for most of training, corresponding to a very negative AUM (red region)."),r.a.createElement(f.o,{placement:"bottom",isOpen:this.state.teaserTooltipOpen,target:"teaser-info",toggle:this.toggleTeaserTooltip},"The two images taken from CIFAR10, where 40% of training samples are mislabeled. Logits/margins/AUMs come from a ResNet-32 model.")),r.a.createElement(R,null,r.a.createElement(M,null,"Noteworthy Results"),r.a.createElement(j,null,"CIFAR100"),r.a.createElement("p",null,"We identify 13% of training data that might be mislabeled/ambiguous/harmful to generalization. Simply these data improves error (with a ResNet-32) ",r.a.createElement("strong",null,"from 33.0% to 31.8%"),"."),r.a.createElement("div",{className:"text-center"},r.a.createElement("figure",null,r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-md-2 col-3 offset-md-2"},r.a.createElement("img",{src:Re.a,className:"figure-img round fluid",alt:"Mislabeled CIFAR100 Sample: Cloud",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-2 col-3"},r.a.createElement("img",{src:De.a,className:"figure-img round fluid",alt:"Mislabeled CIFAR100 Sample: Willow Tree",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-2 col-3"},r.a.createElement("img",{src:We.a,className:"figure-img round fluid",alt:"Mislabeled CIFAR100 Sample: Porcupine",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-2 col-3"},r.a.createElement("img",{src:Ue.a,className:"figure-img round fluid",alt:"Mislabeled CIFAR100 Sample: Telephone",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}}))),r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-md-2 col-3 offset-md-2"},r.a.createElement("img",{src:Fe.a,className:"figure-img round fluid",alt:"Mislabeled CIFAR100 Sample: Rabbit",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-2 col-3"},r.a.createElement("img",{src:_e.a,className:"figure-img round fluid",alt:"Mislabeled CIFAR100 Sample: Plate",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-2 col-3"},r.a.createElement("img",{src:Ke.a,className:"figure-img round fluid",alt:"Mislabeled CIFAR100 Sample: Beetle",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-2 col-3"},r.a.createElement("img",{src:Ye.a,className:"figure-img round fluid",alt:"Mislabeled CIFAR100 Sample: Forest",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}}))),r.a.createElement("figcaption",{className:"figure-caption pt-2"},"Example images from CIFAR100 with large AUM."))),r.a.createElement(j,null,"ImageNet"),r.a.createElement("p",null,"We identify that 2% of ImageNet data is potentially mislabeled. (This low number is expected, due to ImageNet's rigorous annotation process.) Removing these data does not significantly change ResNet-50 error."),r.a.createElement("div",{className:"text-center"},r.a.createElement("figure",null,r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:Ce.a,className:"figure-img round fluid",alt:"Mislabeled ImageNet Sample: Qual",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:Ie.a,className:"figure-img round fluid",alt:"Mislabeled ImageNet Sample: Cannon",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:Me.a,className:"figure-img round fluid",alt:"Mislabeled ImageNet Sample: Bow Tie",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:je.a,className:"figure-img round fluid",alt:"Mislabeled ImageNet Sample: Coral Fungus",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}}))),r.a.createElement("figcaption",{className:"figure-caption pt-2"},"Example images from ImageNet with large AUM. (See ",r.a.createElement(O,{href:"#example-mislabeled"},"the mislabeled images above")," for more high-AUM examples.)"))),r.a.createElement(j,null,"WebVision-50"),r.a.createElement("p",null,'This dataset is a standard benchmark for "weakly-labeled" learning. We identify and remove 17% of the data, improving accuracy from 21.4% to 19.8% with a ResNet-50 model.'),r.a.createElement("div",{className:"text-center"},r.a.createElement("figure",null,r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:Xe.a,className:"figure-img round fluid",alt:"Mislabeled WebVision50 Sample: Indigo Bunting",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:et.a,className:"figure-img round fluid",alt:"Mislabeled WebVision50 Sample: Tiger Shark",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:at.a,className:"figure-img round fluid",alt:"Mislabeled WebVision50 Sample: Electric Ray",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:rt.a,className:"figure-img round fluid",alt:"Mislabeled WebVision50 Sample: Common Newt",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}}))),r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:it.a,className:"figure-img round fluid",alt:"Mislabeled WebVision50 Sample: Tailed Frog",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:ot.a,className:"figure-img round fluid",alt:"Mislabeled WebVision50 Sample: Goldfinch",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:mt.a,className:"figure-img round fluid",alt:"Mislabeled WebVision50 Sample: Spotted Salamander",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}})),r.a.createElement("div",{className:"col-md-3 col-6"},r.a.createElement("img",{src:pt.a,className:"figure-img round fluid",alt:"Mislabeled WebVision50 Sample: European Fire Salamander",style:{maxWidth:"100%",height:"auto",maxHeight:"256px"}}))),r.a.createElement("figcaption",{className:"figure-caption pt-2"},"Example images from WebVision50 with large AUM.")))),r.a.createElement(R,null,r.a.createElement(M,null,"Code"),r.a.createElement("p",null,"We offer a simple PyTorch library (written by ",r.a.createElement(O,{href:"http://www.jshapiro.info/"},"Josh Shapiro"),") for computing the AUM statistic:"),r.a.createElement(ne,{className:"shell text-center shadow-subtle pl-4 pr-4 pt-0 pb-0 mb-3 mt-3",style:{fontSize:"1.25em"}},"\npip install aum\n                "),r.a.createElement("p",null,"This module provides a wrapper around standard PyTorch datasets, as well a as a mechanism for recording the AUM statistic from classification logits. It can be incorporated into any PyTorch classififer in ~10 lines of code."),r.a.createElement(ne,{className:"python shadow-subtle pl-4 pr-4 pt-0 pb-0 mb-3 mt-3"},"\nmodel.train()\nfor batch in loader:\n    inputs, targets, sample_ids = batch\n    logits = model(inputs)\n    records = aum_calculator.update(logits, targets, sample_ids)\n    # ...\n                ")),r.a.createElement(R,{id:"list_of_mislabeled_examples"},r.a.createElement(M,null,"List of Mislabeled Examples in CIFAR"),"The following are list of highly-suspicious/low-quality samples identified in the CIFAR dataset. It countains the training set index, the assigned-class label, as well as the AUM score.",r.a.createElement("ul",null,r.a.createElement("li",null,r.a.createElement(O,{href:dt.a},"List of mislabeled CIFAR10 training data")),r.a.createElement("li",null,r.a.createElement(O,{href:ft.a},"List of mislabeled CIFAR100 training data")))),r.a.createElement(R,null,r.a.createElement(M,null,"FAQ"),r.a.createElement("p",{className:"mb-1"},r.a.createElement("strong",null,"How do i determine which samples are mislabeled from the AUM statistic?")),r.a.createElement("p",{className:"ml-4"},"AUM provides a ranking of all training points (lower = more likely to be mislabeled). To learn an AUM value that separates clean and mislabeled data, we provide a method of ",r.a.createElement("strong",null,"threshold samples")," (described in Section 3 of ",r.a.createElement(O,{href:"https://arxiv.org/abs/2001.10528"},"the paper"),"). Alternatively, if you have access to a clean validation set, you can run a grid search to find the optimal AUM threshold.")),r.a.createElement(R,null,r.a.createElement(M,null,"References"),r.a.createElement("blockquote",{className:"text-center mt-2 mb-3"},"Pleiss, G., Zhang, T., Elenberg, E. R., & Weinberger, K. Q. ",r.a.createElement("strong",null,"Identifying Mislabeled Data using the Area Under the Margin Ranking.")," In ",r.a.createElement("em",null,"Neural Information Processing Systems")," (2020)."),r.a.createElement("ul",null,r.a.createElement("li",null,r.a.createElement(O,{href:"https://arxiv.org/abs/2001.10528"},"Paper on ArXiV")),r.a.createElement("li",null,r.a.createElement("button",{className:"btn btn-link p-0",type:"button",onClick:this.toggleBibtexModal},"BibTeX")),r.a.createElement("li",null,r.a.createElement(O,{href:"https://github.com/asappresearch/aum"},"Code")," (written by ",r.a.createElement(O,{href:"http://www.jshapiro.info/"},"Josh Shaprio"),")")),r.a.createElement(f.e,{size:"lg",isOpen:this.state.bibtexModalOpen,toggle:this.toggleBibtexModal},r.a.createElement(f.g,{toggle:this.toggleBibtexModal},"BibTeX"),r.a.createElement(f.f,null,r.a.createElement("pre",null,"\n@inproceedings{pleiss2020identifying,\n  title={Identifying Mislabeled Data using the Area Under the Margin Ranking},\n  author={Pleiss, Geoff and Zhang, Tianyi and Elenberg, Ethan R. and Weinberger, Kilian Q.},\n  booktitle={Neural Information Processing Systems},\n  year={2020}\n}\n\t\t\t\t\t\t\t\t\t\t"))))))))}}]),a}(r.a.Component),Et=a(68),yt=a.n(Et),vt=a(69),wt=a.n(vt),xt=a(70),Nt=a.n(xt),kt=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement("div",null,r.a.createElement("section",{className:"pt-8 pb-8"},r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"row pt-4 pb-8"},r.a.createElement("div",{className:"col-md-12"},r.a.createElement(S,null,"Complete List of Publications by Topic"),r.a.createElement(B,{id:"uq"},"Uncertainty Quantification"),r.a.createElement(L,{indent:!0},r.a.createElement(U,{title:"Theoretical Limitations of Ensembles in the Age of Overparameterization",authors:["Niclas Dern","John P. Cunningham","Geoff Pleiss"],arxiv:"https://arxiv.org/abs/2410.16201",pdf:"https://arxiv.org/pdf/2410.16201.pdf",github:"https://github.com/nic-dern/theoretical-limitations-overparameterized-ensembles",underSubmission:!0,isNew:!0,year:"2024"}),r.a.createElement(U,{title:"Sharp Calibrated Gaussian Processes",authors:["Alexandre Capone","Sandra Hirche","Geoff Pleiss"],arxiv:"https://arxiv.org/abs/2302.11961",pdf:"https://arxiv.org/pdf/2302.11961.pdf",conference:"NeurIPS",year:"2023"}),r.a.createElement(U,{title:"Posterior and Computational Uncertainty in Gaussian Processes",authors:["Jonathan Wenger","Geoff Pleiss","Marvin Pf\xf6rtner","Philipp Hennig","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2205.15449",pdf:"https://arxiv.org/pdf/2205.15449.pdf",github:"https://github.com/JonathanWenger/itergp",conference:"NeurIPS",year:"2022"}),r.a.createElement(U,{title:"Deep Ensembles Work, But Are They Necessary?",authors:["Taiga Abe*","E. Kelly Buchanan*","Geoff Pleiss","Richard Zemel","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2202.06985",pdf:"https://arxiv.org/pdf/2202.06985.pdf",github:"https://github.com/cellistigs/interp_ensembles",talk:"https://www.youtube.com/watch?v=703FzYv-j9o&ab_channel=VectorInstitute",conference:"NeurIPS",year:"2022"}),r.a.createElement(U,{title:"On Fairness and Calibration",authors:["Geoff Pleiss*","Manish Raghavan*","Felix Wu","Jon Kleinberg","Kilian Q. Weinberger"],conference:"NeurIPS",year:"2017",arxiv:"https://arxiv.org/abs/1709.02012",pdf:"https://arxiv.org/pdf/1709.02012.pdf",github:"https://github.com/gpleiss/equalized_odds_and_calibration"}),r.a.createElement(U,{title:"On Calibration of Modern Neural Networks",authors:["Chuan Gao*","Geoff Pleiss*","Yu Sun*","Kilian Q. Weinberger"],conference:"ICML",year:"2017",website:"/blog/nn_calibration.html",arxiv:"https://arxiv.org/abs/1706.04599",pdf:"https://arxiv.org/pdf/1706.04599.pdf",github:"https://github.com/gpleiss/temperature_scaling",talk:"https://vimeo.com/238242536"})),r.a.createElement(B,{id:"bo"},"Bayesian Optimization"),r.a.createElement(L,{indent:!0},r.a.createElement(U,{title:"Approximation-Aware Bayesian Optimization",authors:["Natalie Maus","Kyurae Kim","Geoff Pleiss","David Eriksson","John P. Cunningham","Jacob R. Gardner"],arxiv:"https://arxiv.org/abs/2406.04308",pdf:"https://arxiv.org/pdf/2406.04308.pdf",github:"https://github.com/nataliemaus/improvement-vi",conference:"NeurIPS",year:"2024"}),r.a.createElement(U,{title:"A Sober Look at LLMs for Material Discovery: Are They Actually Good for Bayesian Optimization Over Molecules?",authors:["Agustinus Kristiadi","Felix Strieth-Kalthoff","Marta Skreta","Pascal Poupart","Al\xe1n Aspuru-Guzik","Geoff Pleiss"],conference:"ICML",arxiv:"https://arxiv.org/abs/2402.05015",pdf:"https://arxiv.org/pdf/2402.05015.pdf",github:"https://github.com/wiseodd/lapeft-bayesopt",year:"2024"}),r.a.createElement(U,{title:"Fast Matrix Square Roots with Applications to Gaussian Processes and Bayesian Optimization",authors:["Geoff Pleiss","Martin Jankowiak","David Eriksson","Anil Damle","Jacob R. Gardner"],arxiv:"https://arxiv.org/abs/2006.11267",pdf:"https://arxiv.org/pdf/2006.11267.pdf",github:"https://arxiv.org/pdf/2102.06695",talk:"https://slideslive.com/38936908/fast-matrix-square-roots-with-applications-to-gaussian-processes-and-bayesian-optimization?ref=speaker-27667-latest",conference:"NeurIPS",year:"2020"})),r.a.createElement(B,{id:"reliable-nn"},"Deep Learning"),r.a.createElement(L,{indent:!0},r.a.createElement(U,{title:"Theoretical Limitations of Ensembles in the Age of Overparameterization",authors:["Niclas Dern","John P. Cunningham","Geoff Pleiss"],arxiv:"https://arxiv.org/abs/2410.16201",pdf:"https://arxiv.org/pdf/2410.16201.pdf",github:"https://github.com/nic-dern/theoretical-limitations-overparameterized-ensembles",underSubmission:!0,isNew:!0,year:"2024"}),r.a.createElement(U,{title:"Pathologies of Predictive Diversity in Deep Ensembles",authors:["Taiga Abe","E. Kelly Buchanan","Geoff Pleiss","John P. Cunningham"],award:"featured paper",arxiv:"https://arxiv.org/abs/2302.00704",pdf:"https://arxiv.org/pdf/2302.00704.pdf",talk:"https://www.youtube.com/watch?v=LINT01z05Bs",conference:"TMLR",year:"2024"}),r.a.createElement(U,{title:"Deep Ensembles Work, But Are They Necessary?",authors:["Taiga Abe*","E. Kelly Buchanan*","Geoff Pleiss","Richard Zemel","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2202.06985",pdf:"https://arxiv.org/pdf/2202.06985.pdf",github:"https://github.com/cellistigs/interp_ensembles",talk:"https://www.youtube.com/watch?v=703FzYv-j9o&ab_channel=VectorInstitute",conference:"NeurIPS",year:"2022"}),r.a.createElement(U,{title:"The Limitations of Large Width in Neural Networks: A Deep Gaussian Process Perspective",authors:["Geoff Pleiss","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2106.06529",pdf:"https://arxiv.org/pdf/2106.06529.pdf",conference:"NeurIPS",github:"https://github.com/gpleiss/limits_of_large_width",talk:"https://slideslive.com/38967621/the-limitations-of-large-width-in-neural-networks-a-deep-gaussian-process-perspective?ref=search-presentations-geoff+pleiss",year:"2021"}),r.a.createElement(U,{title:"Identifying Mislabeled Data using the Area Under the Margin Ranking",authors:["Geoff Pleiss","Tianyi Zhang","Ethan R. Elenberg","Kilian Q. Weinberger"],website:"/blog/aum.html",arxiv:"https://arxiv.org/abs/2001.10528",pdf:"https://arxiv.org/pdf/2001.10528.pdf",github:"https://github.com/asappresearch/aum",talk:"https://slideslive.com/38936900/identifying-mislabeled-data-using-the-area-under-the-margin-ranking?ref=speaker-27667-latest",conference:"NeurIPS",year:"2020"}),r.a.createElement(U,{title:"Snapshot Ensembles: Train 1, get M for free",authors:["Gao Huang*","Yixuan Li*","Geoff Pleiss","Zhuang Liu","John Hopcroft","Kilian Q. Weinberger"],conference:"ICLR",year:"2017",arxiv:"https://arxiv.org/abs/1704.00109",pdf:"https://arxiv.org/pdf/1704.00109.pdf",github:"https://github.com/gaohuang/SnapshotEnsemble"}),r.a.createElement(U,{title:"On Calibration of Modern Neural Networks",authors:["Chuan Gao*","Geoff Pleiss*","Yu Sun*","Kilian Q. Weinberger"],conference:"ICML",year:"2017",website:"/blog/nn_calibration.html",arxiv:"https://arxiv.org/abs/1706.04599",pdf:"https://arxiv.org/pdf/1706.04599.pdf",github:"https://github.com/gpleiss/temperature_scaling",talk:"https://vimeo.com/238242536"})),r.a.createElement(B,{id:"nla"},"Scalable Gaussian Processes via Numerical Methods"),r.a.createElement(L,{indent:!0},r.a.createElement(U,{title:"Computation-Aware Gaussian Processes: Model Selection And Linear-Time Inference",authors:["Jonathan Wenger","Kaiwen Wu","Philipp Hennig","Jacob R. Gardner","Geoff Pleiss","John P. Cunningham"],isNew:!0,arxiv:"https://arxiv.org/abs/2411.01036",pdf:"https://arxiv.org/pdf/2411.01036.pdf",github:"https://github.com/cornellius-gp/gpytorch/blob/e0e8cd5365e7eea72befaa02d644f588984fd337/gpytorch/models/computation_aware_gp.py",conference:"NeurIPS",year:"2024"}),r.a.createElement(U,{title:"Computation-Aware Gaussian Processes: Model Selection And Linear-Time Inference",authors:["Jonathan Wenger","Kaiwen Wu","Philipp Hennig","Jacob R. Gardner","Geoff Pleiss","John P. Cunningham"],conference:"NeurIPS",year:"2024"}),r.a.createElement(U,{title:"Large-Scale Gaussian Processes via Alternating Projection",authors:["Kaiwen Wu","Jonathan Wenger","Hadyn Jones","Geoff Pleiss","Jacob R. Gardner"],arxiv:"https://arxiv.org/abs/2310.17137",pdf:"https://arxiv.org/pdf/2310.17137.pdf",conference:"AISTATS",github:"https://github.com/kayween/alternating-projection-for-gp",year:"2024"}),r.a.createElement(U,{title:"CoLA: Exploiting Compositional Structure for Automatic and Efficient Numerical Linear Algebra",authors:["Andres Potapczynski*","Marc Anton Finzi*","Geoff Pleiss","Andrew Gordon Wilson"],arxiv:"https://arxiv.org/abs/2309.03060",pdf:"https://arxiv.org/pdf/2309.03060.pdf",github:"https://github.com/wilson-labs/cola",conference:"NeurIPS",year:"2023"}),r.a.createElement(U,{title:"Posterior and Computational Uncertainty in Gaussian Processes",authors:["Jonathan Wenger","Geoff Pleiss","Marvin Pf\xf6rtner","Philipp Hennig","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2205.15449",pdf:"https://arxiv.org/pdf/2205.15449.pdf",github:"https://github.com/JonathanWenger/itergp",conference:"NeurIPS",year:"2022"}),r.a.createElement(U,{title:"Preconditioning for Scalable Gaussian Process Hyperparameter Optimization",authors:["Jonathan Wenger","Geoff Pleiss","Philipp Hennig","John P. Cunningham","Jacob R. Gardner"],arxiv:"https://arxiv.org/abs/2107.00243",pdf:"https://arxiv.org/pdf/2107.00243.pdf",github:"https://github.com/cornellius-gp/gpytorch",award:"long oral",conference:"ICML",year:"2022",talk:"https://slideslive.com/38983179/preconditioning-for-scalable-gaussian-process-hyperparameter-optimization?ref=search-presentations-geoff+pleiss"}),r.a.createElement(U,{title:"Bias-Free Scalable Gaussian Processes via Randomized Truncations",authors:["Andres Potapczynski*","Luhuan Wu*","Dan Biderman*","Geoff Pleiss","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2102.06695",pdf:"https://arxiv.org/pdf/2102.06695",conference:"ICML",github:"https://github.com/cunningham-lab/RTGPS",year:"2021",talk:"https://slideslive.com/38959632/biasfree-scalable-gaussian-processes-via-randomized-truncations?ref=search-presentations-geoff+pleiss"}),r.a.createElement(U,{title:"A Scalable and Flexible Framework for Gaussian Processes via Matrix-Vector Multiplication",authors:["Geoff Pleiss"],pdf:Nt.a,thesis:!0,year:"2020"}),r.a.createElement(U,{title:"Fast Matrix Square Roots with Applications to Gaussian Processes and Bayesian Optimization",authors:["Geoff Pleiss","Martin Jankowiak","David Eriksson","Anil Damle","Jacob R. Gardner"],arxiv:"https://arxiv.org/abs/2006.11267",pdf:"https://arxiv.org/pdf/2006.11267.pdf",github:"https://arxiv.org/pdf/2102.06695",talk:"https://slideslive.com/38936908/fast-matrix-square-roots-with-applications-to-gaussian-processes-and-bayesian-optimization?ref=speaker-27667-latest",conference:"NeurIPS",year:"2020"}),r.a.createElement(U,{title:"Exact Gaussian Processes on a Million Data Points",authors:["Ke Alexander Wang*","Geoff Pleiss*","Jacob R. Gardner","Stephen Tyree","Kilian Q. Weinberger","Andrew Gordon Wilson"],arxiv:"https://arxiv.org/abs/1903.08114",pdf:"https://arxiv.org/pdf/1903.08114",conference:"NeurIPS",year:"2019",github:"https://github.com/cornellius-gp/gpytorch/blob/master/examples/01_Simple_GP_Regression/Simple_MultiGPU_GP_Regression.ipynb"}),r.a.createElement(U,{title:"GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration",authors:["Jacob R. Gardner*","Geoff Pleiss*","David Bindel","Kilian Q. Weinberger","Andrew Gordon Wilson"],arxiv:"https://arxiv.org/abs/1809.11165",pdf:"https://arxiv.org/pdf/1809.11165.pdf",award:"spotlight",conference:"NeurIPS",year:"2018",talk:"https://www.videoken.com/embed/QcFGBPNh24E?tocitem=101",github:"https://github.com/cornellius-gp/gpytorch"}),r.a.createElement(U,{title:"Constant-Time Predictive Distributions for Gaussian Processes",authors:["Geoff Pleiss","Jacob R. Gardner","Kilian Q. Weinberger","Andrew Gordon Wilson"],conference:"ICML",year:"2018",arxiv:"https://arxiv.org/abs/1803.06058",pdf:"https://arxiv.org/pdf/1803.06058.pdf",github:"https://github.com/cornellius-gp/gpytorch"}),r.a.createElement(U,{title:"Product Kernel Interpolation for Scalable Gaussian Processes",authors:["Jacob R. Gardner","Geoff Pleiss","Ruihan Wu","Kilian Q. Weinberger","Andrew Gordon Wilson"],conference:"AISTATS",year:"2018",arxiv:"https://arxiv.org/abs/1802.08903",pdf:"https://arxiv.org/pdf/1802.08903.pdf",github:"https://github.com/cornellius-gp/gpytorch"})),r.a.createElement(B,{id:"spatiotemporal"},"Spatiotemporal Modeling"),r.a.createElement(L,{indent:!0},r.a.createElement(U,{title:"Variational Nearest Neighbor Gaussian Processes",authors:["Luhuan Wu","Geoff Pleiss","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2202.01694",pdf:"https://arxiv.org/pdf/2202.01694",conference:"ICML",year:"2022",github:"https://docs.gpytorch.ai/en/latest/examples/04_Variational_and_Approximate_GPs/VNNGP.html",talk:"https://slideslive.com/38983939/vnngp-variational-nearest-neighbor-gaussian-process?ref=search-presentations-geoff+pleiss"}),r.a.createElement(U,{title:"Scalable Cross Validation Losses for Gaussian Process Models",authors:["Martin Jankowiak","Geoff Pleiss"],arxiv:"https://arxiv.org/abs/2105.11535",pdf:"https://arxiv.org/pdf/2105.11535.pdf",techReport:!0,year:"2021"}),r.a.createElement(U,{title:"Hierarchical Inducing Point Gaussian Process for Inter-domain Observations",authors:["Luhuan Wu*","Andrew Miller*","Lauren Anderson","Geoff Pleiss","David Blei","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2103.00393",pdf:"https://arxiv.org/pdf/2103.00393.pdf",github:"https://github.com/cunningham-lab/hipgp",conference:"AISTATS",year:"2021"}),r.a.createElement(U,{title:"Potential Predictability of Regional Precipitation and Discharge Extremes Using Synoptic-Scale Climate Information via Machine Learning",authors:["James Knighton","Geoff Pleiss","Elizabeth Carter","Steven Lyon","M Todd Walter","Scott Steinschneider"],pdf:wt.a,conference:"Journal of Hydrometeorology",year:"2019"})),r.a.createElement(B,{id:"prob-modeling"},"Probabilistic Modeling"),r.a.createElement(L,{indent:!0},r.a.createElement(U,{title:"How Inductive Bias in Machine Learning Aligns with Optimality in Economic Dynamics",authors:["Mahdi Ebrahimi Kahou","James Yu","Jesse Perla","Geoff Pleiss"],arxiv:"https://arxiv.org/abs/2406.01898",pdf:"https://arxiv.org/pdf/2406.01898.pdf",underSubmission:!0,year:"2024"}),r.a.createElement(U,{title:"Harnessing Interpretable and Unsupervised Machine Learning to Address Big Data From Modern X-Ray Diffraction",authors:["Jordan Venderley","Michael Matty","Krishnanand Mallayya","Matthew Krogstad","Jacob Ruff","Geoff Pleiss","Varsha Kishore","David Mandrus","Daniel Phelan","Lekhanath Poudel","Andrew Gordon Wilson","Kilian Q. Weinberger","Puspa Upreti","Michael R. Norman","Stephan Rosenkranz","Ray Osborn","Eun-Ah Kim"],arxiv:"https://arxiv.org/abs/2008.03275",pdf:"https://arxiv.org/pdf/2008.03275.pdf",conference:"Proceedings of the National Academy of Sciences",year:"2022"}),r.a.createElement(U,{title:"Rectangular Flows for Manifold Learning",authors:["Anthony L. Caterini*","Gabriel Loaiza-Ganem*","Geoff Pleiss","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2106.01413",pdf:"https://arxiv.org/pdf/2106.01413.pdf",conference:"NeurIPS",year:"2021",github:"https://github.com/layer6ai-labs/rectangular-flows",talk:"https://slideslive.com/38966976/rectangular-flows-for-manifold-learning-proceedings-of-neural-information-processing-systems?ref=search-presentations-geoff+pleiss"}),r.a.createElement(U,{title:"The Limitations of Large Width in Neural Networks: A Deep Gaussian Process Perspective",authors:["Geoff Pleiss","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2106.06529",pdf:"https://arxiv.org/pdf/2106.06529.pdf",conference:"NeurIPS",github:"https://github.com/gpleiss/limits_of_large_width",talk:"https://slideslive.com/38967621/the-limitations-of-large-width-in-neural-networks-a-deep-gaussian-process-perspective?ref=search-presentations-geoff+pleiss",year:"2021"}),r.a.createElement(U,{title:"Uses and Abuses of the Cross-Entropy Loss: Case Studies in Modern Deep Learning",authors:["Elliott Gordon-Rodriguez","Gabriel Loaiza-Ganem","Geoff Pleiss","John P. Cunningham"],arxiv:"https://arxiv.org/abs/2011.05231",pdf:"https://arxiv.org/pdf/2011.05231.pdf",conference:"NeurIPS \"I Can't Believe It's Not Better!\" Workshop",github:"https://github.com/cunningham-lab/cb_and_cc",year:"2020",talk:"https://slideslive.com/38942667/uses-and-abuses-of-the-crossentropy-loss-case-studies-in-modern-deep-learning?ref=search-presentations-geoff+pleiss"}),r.a.createElement(U,{title:"Deep Sigma Point Processes",authors:["Martin Jankowiak","Geoff Pleiss","Jacob R. Gardner"],arxiv:"https://arxiv.org/abs/2002.09112",pdf:"https://arxiv.org/pdf/2002.09112.pdf",github:"https://github.com/cornellius-gp/gpytorch/blob/master/examples/05_Deep_Gaussian_Processes/Deep_Sigma_Point_Processes.ipynb",conference:"UAI",year:"2020"}),r.a.createElement(U,{title:"Parametric Gaussian Process Regressors",authors:["Martin Jankowiak","Geoff Pleiss","Jacob R. Gardner"],arxiv:"https://arxiv.org/abs/1910.07123",pdf:"https://arxiv.org/pdf/1910.07123.pdf",github:"https://github.com/cornellius-gp/gpytorch/blob/master/examples/04_Variational_and_Approximate_GPs/Approximate_GP_Objective_Functions.ipynb",conference:"ICML",talk:"https://slideslive.com/38928016/parametric-gaussian-process-regressors?ref=search-presentations-geoff+pleiss",year:"2020"})),r.a.createElement(B,{id:"cv"},"Computer Vision"),r.a.createElement(L,{indent:!0},r.a.createElement(U,{title:"Layerwise proximal replay: A proximal point method for online continual learning.",authors:["Jinsoo Yoo","Yunpeng Liu","Frank Wood","Geoff Pleiss"],conference:"ICML",arxiv:"https://arxiv.org/abs/2402.09542",pdf:"https://arxiv.org/pdf/2402.09542.pdf",github:"https://github.com/plai-group/lpr",year:"2024"}),r.a.createElement(U,{title:"Pseudo-lidar++: Accurate depth for 3d object detection in autonomous driving.",authors:["Yurong You*","Yan Wang*","Wei-Lun Chao*","Divyansh Garg","Geoff Pleiss","Bharath Hariharan","Mark Campbell","Kilian Q. Weinberger"],arxiv:"https://arxiv.org/abs/1906.06310",pdf:"https://arxiv.org/pdf/1906.06310.pdf",github:"https://github.com/mileyan/Pseudo_Lidar_V2",conference:"ICLR",year:"2020"}),r.a.createElement(U,{title:"Convolutional Networks with Dense Connectivity",authors:["Gao Huang*","Zhuang Liu*","Geoff Pleiss","Laurens van der Maaten","Kilian Q. Weinberger"],pdf:yt.a,conference:"Pattern Analysis and Machine Intelligence",github:"https://github.com/gpleiss/efficient_densenet_pytorch",year:"2019"}),r.a.createElement(U,{title:"Deep Feature Interpolation for Image Content Changes",authors:["Paul Upchurch*","Jacob R. Gardner*","Geoff Pleiss","Robert Pless","Noah Snavely","Kavita Bala","Kilian Q. Weinberger"],conference:"CVPR",year:"2017",arxiv:"https://arxiv.org/abs/1611.05507",pdf:"https://arxiv.org/pdf/1611.05507.pdf",github:"https://github.com/paulu/deepfeatinterp"})))))))}}]),a}(r.a.Component),At=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement("div",null,r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"row mt-5"},r.a.createElement("div",{className:"col-md-8 offset-md-2"},V))))}}]),a}(r.a.Component),Pt=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement(u.a,{to:this.props.to,className:"nav-link",active:function(e){var t=e.isActive;e._;return t}},this.props.children)}}]),a}(r.a.Component),Tt=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement("div",null,r.a.createElement("div",{className:"bg-gradient-primary pt-10 pb-5 shadow-bottom"},r.a.createElement("div",{className:"container text-center"},r.a.createElement(I,null,"STAT547U: Topics in Deep Learning Theory"),r.a.createElement(S,{className:"text-light"},"Jan-Feb 2025"))),r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-xs-12 pt-5 mb-5"},r.a.createElement(f.h,{tabs:!0},r.a.createElement(f.i,null,r.a.createElement(Pt,{to:"/teaching/stat547u/"},"Course Homepage")),r.a.createElement(f.i,null,r.a.createElement(Pt,{to:"/teaching/stat547u/syllabus.html"},"Syllabus")),r.a.createElement(f.i,null,r.a.createElement(Pt,{to:"/teaching/stat547u/final.html"},"Final Paper Reading Assignment")),r.a.createElement(f.i,null,r.a.createElement(O,{className:"nav-link",href:"https://canvas.ubc.ca/courses/158224"},"Canvas Course Page")))),r.a.createElement(p.b,null))))}}]),a}(r.a.Component),Ct=a(71),Ot=a(72),It=a.n(Ot),St=a(73),Mt=a.n(St),Bt=a(74),jt=a.n(Bt),Gt=a(75),Rt=a.n(Gt),zt=a(76),Dt=a.n(zt),Lt={introLecture:It.a,rkhsLecture:Mt.a,doubleDescentLecture:jt.a,rmtLecture:Rt.a,implicitRegLecture:Dt.a},Wt=a(77),Jt=a.n(Wt),Ut=a(78),Ht=a.n(Ut),Ft=["07 Jan 2025","09 Jan 2025","14 Jan 2025","16 Jan 2025","21 Jan 2025","23 Jan 2025","28 Jan 2025","30 Jan 2025","04 Feb 2025","06 Feb 2025","11 Feb 2025","13 Feb 2025"],Vt={assignment1:r.a.createElement("span",null,r.a.createElement(O,{href:Jt.a},"Diagnostic problem set")," due on Tues, Jan 14."," ","(",r.a.createElement(O,{href:Ht.a},"TeX template")," and"," ",r.a.createElement(O,{href:"../../math_commands.tex"},"math_commands.tex")," macros file. )"),assignment2:r.a.createElement("span",null,r.a.createElement(O,{href:"syllabus.html#final-paper-reading-assignment",inside:!0},"Final project intermediate check-in")," ","due on Tues, Feb 04.")};var _t=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=0;return r.a.createElement(R,{id:"schedule",first:!0},r.a.createElement(M,null,"Schedule"),r.a.createElement("p",null,"Subject to change; check ",r.a.createElement(O,{inside:!0,href:"#announcements"},"announcements")," and Canvas!."),r.a.createElement(f.n,{striped:!0,hover:!0},r.a.createElement("thead",null,r.a.createElement("tr",null,r.a.createElement("th",null,"Class/Date"),r.a.createElement("th",null,"Class Topic"),r.a.createElement("th",null,"Reading Due"),r.a.createElement("th",null,"Resources"))),r.a.createElement("tbody",null,Ct.map((function(t){return"class"===t.type?r.a.createElement("tr",null,r.a.createElement("td",null,"Class ",e+=1," (",(a=Ft[e-1],new Date(Date.parse(a)).toLocaleDateString("en-US",{weekday:"short",month:"short",day:"2-digit"})),")"),r.a.createElement("td",null,t.topic),r.a.createElement("td",null,r.a.createElement(O,{href:t.readingUrl},t.readingTitle),t.note?r.a.createElement("div",null,"(",t.note,")"):r.a.createElement("span",null)),r.a.createElement("td",null,t.lectureNotes?r.a.createElement(O,{className:"btn btn-pdf btn-sm",role:"button",href:Lt[t.lectureNotes]},"Lecture Notes"):r.a.createElement("span",null),(t.links||[]).map((function(e){return r.a.createElement(O,{className:"btn btn-info btn-sm",role:"button",href:e.url},e.name)})))):"section"===t.type?r.a.createElement("tr",null,r.a.createElement("td",{colSpan:"4",className:"text-center"},r.a.createElement("em",null,t.topic),t.assignment?r.a.createElement("br",null):r.a.createElement("span",null),t.assignment?r.a.createElement("span",null,Vt[t.assignment]):r.a.createElement("span",null))):r.a.createElement("div",null);var a})))))}}]),a}(r.a.Component),Zt=a(27),Kt=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement("div",{className:"col-12"},r.a.createElement(R,{first:!0},r.a.createElement(M,null,"Final Paper Presentation Assignment"),r.a.createElement("p",null,"You will choose one of the following papers to read in-depth throughout the course. At the end of the semster, you will have a 30 minute oral examination on your understanding of the paper. (I will post a list of specific questions to prepare later in the semester.) See ",r.a.createElement(O,{inside:!0,href:"syllabus.html#final-paper-reading-assignment"},"the syllabus")," ","for a detailed description of the assignment."),r.a.createElement("p",null,"If you have a paper in mind that is not on this list, chat with me!"),r.a.createElement(f.n,{striped:!0,hover:!0},r.a.createElement("thead",null,r.a.createElement("tr",null,r.a.createElement("th",null,"Title"),r.a.createElement("th",null,"Topics"),r.a.createElement("th",null,"Authors"),r.a.createElement("th",null,"Venue"),r.a.createElement("th",null,"Link"))),r.a.createElement("tbody",null,Zt.filter((function(e){return e.final})).sort((function(e,t){return e.tags<t.tags?-1:1})).map((function(e){return r.a.createElement("tr",{key:e.id},r.a.createElement("td",null,e.title),r.a.createElement("td",null,e.tags),r.a.createElement("td",null,e.authors),r.a.createElement("td",null,e.venue,", ",e.year),r.a.createElement("td",null,r.a.createElement(O,{className:"btn btn-pdf btn-sm",role:"button",href:e.url},"PDF")))}))))))}}]),a}(r.a.Component),qt=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=r.a.createElement(O,{href:"https://canvas.ubc.ca/courses/158224"},"Canvas"),t=r.a.createElement(O,{inside:!0,href:"#contact"},"contact me");return r.a.createElement("div",{className:"col-12"},r.a.createElement(R,{first:!0},r.a.createElement("p",null,"This course takes place in the traditional, ancestral and unceded territory of the x\u02b7m\u0259\u03b8k\u02b7\u0259y\u0313\u0259m (",r.a.createElement(O,{href:"https://www.musqueam.bc.ca/"},"Musqueam"),"). It is important to reflect upon this fact as we study, work, and grow on this land. (",r.a.createElement(O,{href:"https://indigenous.ubc.ca"},"https://indigenous.ubc.ca"),".)")),r.a.createElement(R,null,r.a.createElement(M,null,"Course Overview"),r.a.createElement("p",null,r.a.createElement("strong",null,"Description.")," ","The success of neural networks defies classical statistical learning theory. While a detailed analysis of neural networks remains theoretically intractable, recent analyses of high-dimensional linear regression and infinite-width neural networks have shed light on",r.a.createElement("ol",null,r.a.createElement("li",null,"why neural networks optimize well, despite the inherent non-convexity of training, and"),r.a.createElement("li",null,"why neural networks generalize well, despite their overparameterized nature."))),r.a.createElement("p",null,"This course will be a self-contained exploration of recent theoretical results in the theory of neural networks and high-dimensional regression. Students will learn from lectures that simplify complex mathematics and recent research papers that prove theorems in full technical detail. Students will gain familiarity with existing research, common problem setups and simplifying assumptions, and common techniques used to prove theoretical results."),r.a.createElement("p",null,r.a.createElement("strong",null,"Learning objectives.")," ","If we're successful, you will:"),r.a.createElement("ul",null,r.a.createElement("li",null,"articulate the limitations of classical learning theory methods,"),r.a.createElement("li",null,"understand why neural network optimize well despite non-convexity,"),r.a.createElement("li",null,"understand why high-dimensional linear models generalize despite overparameterization,"),r.a.createElement("li",null,"understand how to approximate neural networks with linear models,"),r.a.createElement("li",null,"know how to set up high-dimensional asymptotic proofs,"),r.a.createElement("li",null,"be fluent with the basic mathematical techniques underpinning neural network theory (linear algebra, probability theory, etc), and"),r.a.createElement("li",null,"become familiar with advanced mathematical techniques necessary for proofs (chaining arguments, random matrix theory, etc.), and"),r.a.createElement("li",null,"gain confidence at reading theoretical machine learning papers.")),r.a.createElement("p",null,r.a.createElement("strong",null,"Prerequisites.")," ","If you are worried that you won't satisfy the following prerequisites, please speak to me after the first class:"),r.a.createElement("ul",null,r.a.createElement("li",null,"one upper-division course in statistics or machine learning (e.g. STAT 460 or CS 540),"),r.a.createElement("li",null,"one course in analysis (e.g. MATH 320),"),r.a.createElement("li",null,"fluency with linear algebra, and"),r.a.createElement("li",null,"(recommended) one upper-division course in probability (e.g. STAT 547C).")),r.a.createElement("p",null,r.a.createElement("strong",null,"Values.")," ","This course will be a safe and inclusive learning environment for all. If you are treated unfairly or disrespectfully\u2014whether by another student or myself\u2014please (1) ",t," directly (if you feel comfortable), (2) submit an ",r.a.createElement(z,null),", or (3) work with the ",r.a.createElement(O,{href:"https://ombudsoffice.ubc.ca/how-we-can-help/"},"UBC ombudsperson office"),". I also aim to accommodate neurodiversity, mental health, and access needs within the course. Please ",t," for special accommodation requests or take advantage of ",r.a.createElement(O,{href:"https://senate.ubc.ca/policies-resources-support-student-success/"},"UBC's student resources"),".")),r.a.createElement(R,null,r.a.createElement(M,null,"Instructor: Geoff Pleiss"),r.a.createElement("p",null,r.a.createElement("strong",null,"About me"),"."," ","I am an assistant professor in the stats department. My research generally encompasses machine learning, with an emphasis on uncertainty quantification and decision making. I work on neural networks\u2014both from theoretical and methodological perspectives\u2014 Bayesian optimization, and spatiotemporal modelling with Gaussian processes."),r.a.createElement("p",null,r.a.createElement("strong",null,"Office hours.")," See ",e," for details. I'll also stick around to chat for ~10 minutes after class."),r.a.createElement("p",null,r.a.createElement("strong",{id:"contact"},"How to contact me"),"."," ","Send me a message through ",e,", the UBC Stats Slack (preferred, if you have access), or email (only if you absolutely need to). Please note that I will not respond on weekends or after 6 PM on weekdays.")),r.a.createElement(R,null,r.a.createElement(M,null,"Learning Activities and Assessment"),r.a.createElement("p",null,"Neural network theory is a challenging subject that cannot be learned passively."," ",r.a.createElement("emph",null,"If you plan to just sit through lectures, you will likely not come away with an understanding of the material.")),r.a.createElement("p",null,"You will learn through the following activities:"),r.a.createElement(j,null,"Lecture"),r.a.createElement("p",null,"Class is where we will cover most of the technical content in this course. I will present the material in self-contained lectures."," ",r.a.createElement("em",null,"Again, you cannot learn the material simply by sitting through lectures.")," ","You are expected to read material before class (see below) and to actively participate with questions and comments."),r.a.createElement(j,null,"Readings and written summaries"),r.a.createElement("p",null,"Most lectures will have required readings that you are expected to complete ",r.a.createElement("em",null,"before")," class. These readings will be a mix of book chapters and some recent (accessible) research and review papers."),r.a.createElement("p",null,"To further facilitate your understanding, you are required to write a half-page summary of each reading (to be uploaded to ",e,"). Each summary should include exactly 4 paragraphs:"),r.a.createElement("ol",null,r.a.createElement("li",null,r.a.createElement("strong",null,"Setting")," (problem formulation, assumptions, etc.)"),r.a.createElement("li",null,r.a.createElement("strong",null,"The Goal and Main Result")," (what is trying to be proved, what other papers have already proved, etc.)"),r.a.createElement("li",null,r.a.createElement("strong",null,"Description of Mathematical Techniques")," (what types of math are used to arrive at each theoretical result)"),r.a.createElement("li",null,r.a.createElement("strong",null,"Points of Confusion")," (what were you not able to understand)")),r.a.createElement("p",null,"You should spend roughly 2 hours on each reading and 1 hour on each written summary."),r.a.createElement(j,null,"Diagnostic assignment"),r.a.createElement("p",null,"There will be a single problem set for this course, ",r.a.createElement("em",null,"which is due on ",e," at the beginning of the second week of class.")," ","This problem set aims to gauge your fluency with linear algebra and probability theory while also setting up the material for the first few lectures. If you give this diagnostic a reasonable effort, you will be well-prepared for the mathematics in this course. If you struggle with it, you will struggle with the rest of the material."),r.a.createElement(j,{id:"final-paper-reading-assignment"},"Final paper reading assignment"),r.a.createElement("p",null,"The final assessment for this course involves ",r.a.createElement("emph",null,"thoroughly")," reading a modern research paper on neural network theory and a 30 minute oral examination to assess your understanding."),r.a.createElement("p",null,"You will select a paper from a ",r.a.createElement(O,{inside:!0,href:"final.html"},"predetermined list"),". All of the papers are quite challenging, with advanced mathematical techniques that will not be covered in class. You will need to spend significant time on the paper (read: 2+ weeks); reading it multiple times and researching the background mathematics necessary to understand the paper."),r.a.createElement("p",null,"During the oral examination, I will ask you about the following aspects of the paper:",r.a.createElement("ui",null,r.a.createElement("li",null,"the problem being solved,"),r.a.createElement("li",null,"related work (what has been studied before),"),r.a.createElement("li",null,"the problem setting,"),r.a.createElement("li",null,"the main theoretical results,"),r.a.createElement("li",null,"sketches of the proof, and"),r.a.createElement("li",null,"limitations of the analysis."))),r.a.createElement("p",null,"To ensure you're on track, there will be a written intermediate check-in assignment, in which you are expected to write a 1-page summary of the paper you have chosen. It should follow the same format as the written summaries of the readings, with the same 4 paragraphs. Each paragraph will be graded on a 2.5-point scale, for a total of 10 points. (The rubric will be the same as the written summaries of the readings, with everything scaled by 1.25.)")),r.a.createElement(R,{id:"assessment"},r.a.createElement(M,null,"Assessment"),r.a.createElement("p",null,"The grades and weightings target the following scale:"),r.a.createElement("ul",null,r.a.createElement("li",null,"An ",r.a.createElement("tt",null,"A-")," represents a cursory understanding of NN theory (e.g. comprehending the lecture material but not the readings)."),r.a.createElement("li",null,"An ",r.a.createElement("tt",null,"A")," represents an in-depth understanding of NN theory (e.g. comprehending the lecture material and readings to a great extent)."),r.a.createElement("li",null,"An ",r.a.createElement("tt",null,"A+")," represents that you are ready to perform research on NN theory (e.g. going above and beyond the course materials).")),r.a.createElement(f.n,{striped:!0,hover:!0},r.a.createElement("thead",null,r.a.createElement("tr",null,r.a.createElement("th",null,"Category"),r.a.createElement("th",null,"Contribution"),r.a.createElement("th",null,"Notes"))),r.a.createElement("tbody",null,r.a.createElement("tr",null,r.a.createElement("td",null,"Class participation"),r.a.createElement("td",null,"10%"),r.a.createElement("td",null,"5%: attending class regularly, 5%: engaging during lecture. (Let me know if you need to miss class.)")),r.a.createElement("tr",null,r.a.createElement("td",null,"Diagnostic assignment"),r.a.createElement("td",null,"15%"),r.a.createElement("td",null,"See description above. It will be worth a total of 60 points, scaled to be worth 15% of your final grade.")),r.a.createElement("tr",null,r.a.createElement("td",null,"Reading summaries"),r.a.createElement("td",null,"40%"),r.a.createElement("td",null,r.a.createElement("p",null,"See description above. There are 6 written summaries, each worth 8 points (2 points per paragraph), for a total of 48 points. Your grade will be ",r.a.createElement("tt",null,"min(40, total_points)"),"."),r.a.createElement("p",null,"Each paragraph will be graded on the following scale: (1 points) demonstrates that you skimmed the reading, (2 points) demonstrates that you read the paper/chapter thoroughly."))),r.a.createElement("tr",null,r.a.createElement("td",null,"Final paper reading assignment"),r.a.createElement("td",null,"35%"),r.a.createElement("td",null,"See description above. The intermediate check-in will be 10 points, and the oral presentation will be 25 points.")))),r.a.createElement("p",null,"Rubrics for all assignments will be available on Canvas."),r.a.createElement(j,null,"Concessions"),r.a.createElement("p",null,"Please ",t," as soon as possible if you will have trouble completing an assignment on time and/or participating in class. I understand the effects of life events, health circumstances (mental or physical), and scheduling, and I will work with you to best structure your learning/assessment. Please also refer to ",r.a.createElement(O,{href:"https://vancouver.calendar.ubc.ca/campus-wide-policies-and-regulations/academic-concession"},"UBC's policies on academic concessions"),".")),r.a.createElement(R,null,r.a.createElement(M,null,"Resources"),r.a.createElement(j,{id:"canvas"},"Canvas"),r.a.createElement("p",{id:"course-canvas"},"We will use ",e," for 1) announcements, 2) discussions, and 3) uploading assignments."),r.a.createElement(j,null,"Readings (required and optional)"),r.a.createElement("p",null,"Please see the ",r.a.createElement(O,{href:"index.html"},"schedule")," for required readings and a bibliography of additional papers related to each lecture."),r.a.createElement(j,{id:"textbook"},"Other References"),r.a.createElement("ul",null,Zt.filter((function(e){return Array.isArray(e.tags)&&1===e.tags.length&&"resource"===e.tags[0]})).map((function(e){return r.a.createElement("li",null,'"',r.a.createElement(O,{href:e.url},e.title),',"'," ",e.authors," (",e.year,").")})))),r.a.createElement(R,null,r.a.createElement(M,null,"Policies and Values"),r.a.createElement("p",null,"UBC provides resources to support student learning and maintaining healthy lifestyles but recognizes that crises sometimes arise. There are additional resources to access, including those for survivors of sexual violence. UBC values respect for the person and ideas of all academic community members. Harassment and discrimination are not tolerated, nor is suppression of academic freedom. UBC provides appropriate accommodation for students with disabilities and religious, spiritual and cultural observances. UBC values academic honesty, and students are expected to acknowledge the ideas generated by others and to uphold the highest academic standards in all of their actions. Details of the policies and how to access support are available "," ",r.a.createElement(O,{href:"http://senate.ubc.ca/policies-resources-support-student-success"},"here"),".")))}}]),a}(r.a.Component),Yt=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement(u.a,{to:this.props.to,className:"nav-link",active:function(e){var t=e.isActive;e._;return t}},this.props.children)}}]),a}(r.a.Component),Qt=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement("div",null,r.a.createElement("div",{className:"bg-gradient-primary pt-10 pb-5 shadow-bottom"},r.a.createElement("div",{className:"container text-center"},r.a.createElement(I,null,"STAT520P: Bayesian Optimization"),r.a.createElement(S,{className:"text-light"},"Oct-Dec 2023"))),r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-xs-12 pt-5 mb-5"},r.a.createElement(f.h,{tabs:!0},r.a.createElement(f.i,null,r.a.createElement(Yt,{to:"/teaching/stat520p/"},"Course Homepage")),r.a.createElement(f.i,null,r.a.createElement(Yt,{to:"/teaching/stat520p/syllabus.html"},"Syllabus")),r.a.createElement(f.i,null,r.a.createElement(Yt,{to:"/teaching/stat520p/papers.html"},"Special Topics Papers")),r.a.createElement(f.i,null,r.a.createElement(O,{className:"nav-link",href:"https://canvas.ubc.ca/courses/135093"},"Canvas Course Page")),r.a.createElement(f.i,null,r.a.createElement(O,{className:"nav-link",href:"https://bayesoptbook.com#download"},"Textbook")),r.a.createElement(f.i,null,r.a.createElement(O,{className:"nav-link",href:"https://github.com/gpleiss/gp_bo_demos"},"Demos")))),r.a.createElement(p.b,null))))}}]),a}(r.a.Component),Xt=a(79),$t=a.n(Xt),ea=a(80),ta=a.n(ea),aa=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=r.a.createElement(O,{href:"https://bayesoptbook.com#download"},"Textbook");return r.a.createElement("div",{className:"col-12"},r.a.createElement(R,{id:"schedule",first:!0},r.a.createElement(M,null,"Schedule"),r.a.createElement("p",null,"Subject to change; check ",r.a.createElement(O,{inside:!0,href:"#announcements"},"announcements")," and Canvas!."),r.a.createElement(f.n,{striped:!0,hover:!0},r.a.createElement("thead",null,r.a.createElement("tr",null,r.a.createElement("th",null,"Class/Date"),r.a.createElement("th",null,"Class Topic"),r.a.createElement("th",null,"Reading Due"),r.a.createElement("th",null,"Assignment Due"))),r.a.createElement("tbody",null,r.a.createElement("tr",null,r.a.createElement("td",null,"Class 1 (Tues, Oct 24)"),r.a.createElement("td",null,"Introduction, course logistics"),r.a.createElement("td",null),r.a.createElement("td",null)),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 2 (Thurs, Oct 26)"),r.a.createElement("td",null,"Gaussian processes",r.a.createElement("br",null),"(",r.a.createElement(O,{href:"../../mvn_cheat_sheet.pdf"},"Cheat sheet on multivariate Gaussians"),")"),r.a.createElement("td",null,e," Ch. 1-2"),r.a.createElement("td",null)),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 3 (Tues, Oct 31)"),r.a.createElement("td",null,"Gaussian processes and kernels",r.a.createElement("br",null),"(",r.a.createElement(O,{href:"https://github.com/gpleiss/gp_bo_demos/blob/main/kernel_demo.ipynb"},"Jupyter demo"),", David Duvenaud's ",r.a.createElement(O,{href:"https://www.cs.toronto.edu/~duvenaud/cookbook/"},"kernel cookbook"),")"),r.a.createElement("td",null,e," Ch. 3, 9.1 (optional)"),r.a.createElement("td",null,r.a.createElement(O,{href:$t.a},"Diagonstic problem set")," ","(",r.a.createElement(O,{href:ta.a},"TeX template")," and"," ",r.a.createElement(O,{href:"../../math_commands.tex"},"math_commands.tex")," macros file)")),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 4 (Thurs, Nov 2)"),r.a.createElement("td",null,"Decision theory and optimization theory"),r.a.createElement("td",null,e," Ch. 5"),r.a.createElement("td",null)),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 5 (Tues, Nov 7) (",r.a.createElement(O,{href:"https://github.com/gpleiss/gp_bo_demos/blob/main/1d_bo_demo.ipynb"},"Jupyter demo")," on BDT acquisition functions)"),r.a.createElement("td",null,"Acquisition functions"),r.a.createElement("td",null,e," Ch. 6-7"),r.a.createElement("td",null,"Project proposal (for those choosing the project final asssessment option)")),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 6 (Thurs, Nov 9) (",r.a.createElement(O,{href:"https://github.com/gpleiss/gp_bo_demos/blob/main/1d_bo_ucb_demo.ipynb"},"Jupyter demo")," on UCB, ",r.a.createElement(O,{href:"https://github.com/gpleiss/gp_bo_demos/blob/main/1d_bo_ts_demo.ipynb"},"Jupyter demo")," on Thompson sampling )"),r.a.createElement("td",null,"Acquisition functions"),r.a.createElement("td",null),r.a.createElement("td",null)),r.a.createElement("tr",null,r.a.createElement("td",{colspan:"4",className:"text-center"},r.a.createElement("em",null,"No Class on Nov 14"),r.a.createElement("br",null),"(Reading Week)")),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 7 (Thurs, Nov 16)"),r.a.createElement("td",null,"Implementation details"),r.a.createElement("td",null,e," Ch. 8, 9.2"),r.a.createElement("td",null,"Short coding assignment")),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 8 (Tues, Nov 21)"),r.a.createElement("td",null,"Special Topic (Multi-Objective BO)"),r.a.createElement("td",null,r.a.createElement(O,{href:"https://arxiv.org/abs/2109.10964"},"Multi-Objective Bayesian Optimization over High-Dimensional Search Spaces")),r.a.createElement("td",null)),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 9 (Thurs, Nov 23)"),r.a.createElement("td",null,"Special Topic (Local BO)"),r.a.createElement("td",null,r.a.createElement(O,{href:"https://arxiv.org/abs/1910.01739"},"Scalable Global Optimization via Local Bayesian")),r.a.createElement("td",null)),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 10 (Tues, Nov 28)"),r.a.createElement("td",null,"Special Topic (Mixed-Space BO)"),r.a.createElement("td",null,r.a.createElement(O,{href:"https://arxiv.org/abs/2210.10199"},"Bayesian Optimization over Discrete and Mixed Spaces via Probabilistic Reparameterization")),r.a.createElement("td",null)),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 11 (Thurs, Nov 30)"),r.a.createElement("td",null,"Special Topic (Causal BO)"),r.a.createElement("td",null,r.a.createElement(O,{href:"https://arxiv.org/abs/2005.11741"},"Causal Bayesian Optimization")),r.a.createElement("td",null)),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 12 (Tues, Dec 5)"),r.a.createElement("td",null,"Special Topic (Preference BO)"),r.a.createElement("td",null,r.a.createElement(O,{href:"https://arxiv.org/abs/1112.5745"},"Bayesian Active Learning for Classification and Preference Learning")),r.a.createElement("td",null)),r.a.createElement("tr",null,r.a.createElement("td",null,"Class 13 (Thurs, Dec 7)"),r.a.createElement("td",null,"Special Topic (Cost-Aware BO)"),r.a.createElement("td",null,r.a.createElement(O,{href:"https://proceedings.mlr.press/v45/Xia15.html"},"Budgeted Bandit Problems with Continuous Random Costs")),r.a.createElement("td",null))))))}}]),a}(r.a.Component),na=a(81),ra=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement("div",{className:"col-12"},r.a.createElement(R,{first:!0},r.a.createElement(M,null,"Special Topics Papers"),r.a.createElement("p",null,"The following is a list of suggested papers top cover in the second half of the course. I am also open to other paper recommendations!"),r.a.createElement(f.n,{striped:!0,hover:!0},r.a.createElement("thead",null,r.a.createElement("tr",null,r.a.createElement("th",null,"Title"),r.a.createElement("th",null,"Topics"),r.a.createElement("th",null,"Authors"),r.a.createElement("th",null,"Venue"),r.a.createElement("th",null,"Link"))),r.a.createElement("tbody",null,na.map((function(e){return r.a.createElement("tr",null,r.a.createElement("td",null,e.Paper),r.a.createElement("td",null,e.Tags),r.a.createElement("td",null,e.Authors),r.a.createElement("td",null,e.Venue||"ArXiV",", ",e.Date),r.a.createElement("td",null,r.a.createElement(O,{className:"btn btn-pdf btn-sm",role:"button",href:e.URL},"PDF")))}))))))}}]),a}(r.a.Component);var la=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=r.a.createElement(O,{href:this.props.link},this.props.title),t=this.props.authors.split(",").map((function(e){return function(e){var t=e.trim().split(" ");return t.slice(0,-1).map((function(e){return e[0]+"."})).join("")+" "+t[t.length-1].replace("~"," ")}(e)})).join(", ").trim(),a=this.props.book?r.a.createElement("em",null,e):r.a.createElement("span",null,'"',e,'"'),n=this.props.venue?r.a.createElement("span",null,"In ",this.props.venue,", "):r.a.createElement("span",null);return r.a.createElement("span",null,t,". ",a,". ",n,this.props.year,".")}}]),a}(r.a.Component),ia=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=r.a.createElement(O,{inside:!0,href:"#textbook"},"textbook"),t=r.a.createElement(O,{href:"https://canvas.ubc.ca/courses/135093"},"Canvas"),a=r.a.createElement(O,{inside:!0,href:"#contact"},"contact me");return r.a.createElement("div",{className:"col-12"},r.a.createElement(R,{first:!0},r.a.createElement("p",null,"This course takes place in the traditional, ancestral and unceded territory of the x\u02b7m\u0259\u03b8k\u02b7\u0259y\u0313\u0259m (",r.a.createElement(O,{href:"https://www.musqueam.bc.ca/"},"Musqueam"),"). It is important to reflect upon this fact as we study, work, and grow on this land. (",r.a.createElement(O,{href:"https://indigenous.ubc.ca"},"https://indigenous.ubc.ca"),".)")),r.a.createElement(R,null,r.a.createElement(M,null,"Course Overview"),r.a.createElement("p",null,r.a.createElement("strong",null,"Description"),". Bayesian optimization (BO) is a well-established probabilistic approach to ",r.a.createElement("em",null,"blackbox optimization"),": the process of optimizing functions that (1) lack an explicit mathematical form and (2) are often expensive to evaluate. While its origins trace back to ",r.a.createElement(O,{href:"https://www.semanticscholar.org/paper/A-versatile-stochastic-model-of-a-function-of-and-Kushner/c8b0970010ee5752d6307f2b008280e2bcac5e63"},"1962"),", BO gained popularity in 2012 when a ",r.a.createElement(O,{href:"Practical Bayesian optimization of machine learning algorithms"},"seminal paper")," noted its efficacy at hyperparameter tuning for machine learning models. Recently, an explosion of developments have made BO a promising approach for challenging design problems, ranging from ",r.a.createElement(O,{href:"https://arxiv.org/abs/2001.01793"},"nuclear fusion control")," to ",r.a.createElement(O,{href:"https://arxiv.org/abs/2201.11872"},"drug discovery"),"."),r.a.createElement("p",null,"This graduate-level topics course aims to provide (1) a rigorous technical introduction of BO, (2) a survey of recent research developments in the field, and (3) the skills needed to utilize BO methods in practice. The first half of the course will be focused on technical foundations, basic algorithms, implementation, and theory (see ",r.a.createElement(O,{inside:!0,href:"#part1-topics"},"below")," for topics). The second half of the course will explore special topics from recent literature, such as high-dimensional optimization, latent-space optimization, grey-box optimization, and/or mixed-feature spaces (see ",r.a.createElement(O,{inside:!0,href:"#part2-topics"},"below")," for potential topics)."),r.a.createElement("p",null,r.a.createElement("strong",null,"Learning objectives"),". If we're successful, you will:"),r.a.createElement("ul",null,r.a.createElement("li",null,"understand the technical foundations underpinning BO,"),r.a.createElement("li",null,"know the current limitations and challenges of using BO,"),r.a.createElement("li",null,"feel confident using BO software, and"),r.a.createElement("li",null,"be able to apply BO to real-world problems, and"),r.a.createElement("li",null,"(optional) be prepared to perform research in BO methodology.")),r.a.createElement("p",null,r.a.createElement("strong",null,"Prerequisites"),". If you are worried that you won't satisfy the following prerequisites, please speak to me after the first class:"),r.a.createElement("ul",null,r.a.createElement("li",null,"one upper-division course in statistics or machine learning (e.g. STAT 460 or CS 540),"),r.a.createElement("li",null,"fluency with Bayes theorem and Gaussian distributions, and"),r.a.createElement("li",null,"experience with Python.")),r.a.createElement("p",null,r.a.createElement("strong",null,"Values"),". This course will be safe and inclusive learning environment for all. I expect everyone to abide by the ",r.a.createElement(O,{href:"../../code_of_conduct.html"},"code of conduct"),". If you are treated unfairly or disrespectfully\u2014whether by another student or myself\u2014please (1) ",a," directly (if you feel comfortable), (2) submit an ",r.a.createElement(z,null),", or (3) work with the ",r.a.createElement(O,{href:"https://ombudsoffice.ubc.ca/how-we-can-help/"},"UBC ombudsperson office"),". I also aim to accommodate neurodiversity, mental health, and access needs within the course. Please ",a," for requests with special accommodation requests, or take advantage of ",r.a.createElement(O,{href:"https://senate.ubc.ca/policies-resources-support-student-success/"},"UBC's student resources"),".")),r.a.createElement(R,null,r.a.createElement(M,null,"Instructor: Geoff Pleiss"),r.a.createElement("p",null,r.a.createElement("strong",null,"About me"),'. I am a new assistant professor in the stats department. My research generally encompasses Gaussian processes/spatiotemporal modeling, Bayesian optimization, and "reliable" deep learning.',r.a.createElement("br",null),r.a.createElement("small",null,"(This is my first course, so please be nice!)")),r.a.createElement("p",null,r.a.createElement("strong",null,"Office hours:")," see ",t," for details. I will also stick around after class for ~10 minutes."),r.a.createElement("p",null,r.a.createElement("strong",{id:"contact"},"How to contact me"),". Send me a message through ",t,", the UBC Stats Slack (preferred, if you have access), or email (only if you absolutely need to). Please note that I will not respond on weekends or after 6PM on weekdays.")),r.a.createElement(R,null,r.a.createElement(M,null,"Learning Activities"),r.a.createElement("p",null,"You will learn through the following activities:"),r.a.createElement("ul",null,r.a.createElement("li",null,r.a.createElement("strong",null,"Attending/participating in class"),".",r.a.createElement("p",null,"Class is where we will cover most of the technical content in this course. We will also have lively discussions on cool applications, current limitations, etc.")),r.a.createElement("li",null,r.a.createElement("strong",null,"Reading textbook chapters")," (first half of the course).",r.a.createElement("p",null,"The textbook chapters will help to solidify the technical foundations that I will cover in lecture.")),r.a.createElement("li",null,r.a.createElement("strong",null,"Reading current research papers")," (second half of the course).",r.a.createElement("p",null,"The research papers will give you a flavor of the current limitations/possibilities of Bayesian optimization.")),r.a.createElement("li",{id:"diagnostic-pset"},r.a.createElement("strong",null,"Completing a diagnostic problem set."),r.a.createElement("p",null,"There will be a single problem set on Gaussian distributions that will be due ",r.a.createElement("em",null,"at the end of the first week of class"),". It will ensure that you are comfortable with the properties of Gaussian distributions, which will be at the center of all the technical content we will discuss throughout this course. If you have experience with Bayesian statistics, this problem set will (hopefully) be a nice review. If you struggle with this problem set, you may have difficulty with the rest of the material in this course."),r.a.createElement("p",null,r.a.createElement("small",null,"(I realize that it's tough having an assignment due within the first week. I will release the problem set before the first of class to give you a head start. I will also provide extensions with no late penalty, provided that you ",a," first.)"))),r.a.createElement("li",{id:"short-coding-exercise"},r.a.createElement("strong",null,"Completing a short coding exercise."),r.a.createElement("p",null,"You will have a short coding exercise to help get you familiar with ",r.a.createElement(O,{href:"https://ax.dev"},"AX")," and/or ",r.a.createElement(O,{href:"https://botorch.org"},"BoTorch"),", the predominant software libraries for Bayesian optimization application and research. The exercise will ensure that you can apply what you learn in class to real-world problems.")),r.a.createElement("li",null,r.a.createElement("strong",null,"Completing a final assessment,")," which will take one of two flavors:")),r.a.createElement("div",{id:"final-assessment"},r.a.createElement(j,{id:"research-project"},"Final Assessment Option 1: Research Project"),r.a.createElement("p",null,"This option is best for students who (1) want to apply Bayesian optimization to a research project/application area, or (2) are interested in Bayesian optimization methodology/theory research. Expect about 4 weeks to start and complete a project. You may work alone or in pairs, and you should contact me before selecting a topic."),r.a.createElement("p",null,r.a.createElement("strong",null,"Double dipping is encouraged!")," (If Bayesian optimization fits into your existing research or another class project, then please use that research/course project as your final for this course!) The deliverables for this option are:"),r.a.createElement(f.n,{striped:!0,hover:!0},r.a.createElement("thead",null,r.a.createElement("tr",null,r.a.createElement("th",null,"Deliverable"),r.a.createElement("th",null,"Date"))),r.a.createElement("tbody",null,r.a.createElement("tr",null,r.a.createElement("td",null,"Project proposal."),r.a.createElement("td",null,"9 Nov 2023.")),r.a.createElement("tr",null,r.a.createElement("td",null,"15-minute final presentation."),r.a.createElement("td",null,"During exams period (after 7 Dec 2023). Exact date TBD.")),r.a.createElement("tr",null,r.a.createElement("td",null,"Code repository and/or written proofs."),r.a.createElement("td",null,"During exams period (after 7 Dec 2023). Exact date TBD.")))),r.a.createElement("p",null,"Note that there is no final report due. However, if your project is theoretical in nature, you should expect to turn in a document with your primary theorems/proofs. More information to follow!"),r.a.createElement(j,{id:"topics-presentation"},"Final Assessment Option 2: Topics Paper Presentation and Reviews"),r.a.createElement("p",null,"For students who don't want to complete a research project, or who simply want to learn as much about BO as possible, you instead have the option of a final assessment geared more towards learning about current research topics."),r.a.createElement("p",null,"In the second half of the course, each class will focus on 1-2 current BO papers. 1-2 students (who choose this final assessment option) will lead the class, giving a 30-60 minute presentation on the selected papers. All other students (except those doing final projects) will be responsible for writing a review/reflection on one of the papers before the start of each class."),r.a.createElement(f.n,{striped:!0,hover:!0,id:"topics-presentation-deliverables"},r.a.createElement("thead",null,r.a.createElement("tr",null,r.a.createElement("th",null,"Deliverable"),r.a.createElement("th",null,"Date"))),r.a.createElement("tbody",null,r.a.createElement("tr",null,r.a.createElement("td",null,"One 30-60 minute presentation on 1-2 current BO papers."),r.a.createElement("td",null,"Between Nov 14 to Dec 7.")),r.a.createElement("tr",null,r.a.createElement("td",null,"6-7 reflections/reviews on current BO papers."),r.a.createElement("td",null,"Every class from Nov 14 to Dec 7.")),r.a.createElement("tr",null,r.a.createElement("td",null,"An additional coding exercise."),r.a.createElement("td",null,"TBD.")))),r.a.createElement("p",null,"More information to follow!"))),r.a.createElement(R,null,r.a.createElement(M,null,"Course Outline"),r.a.createElement(j,null,"Part 1: Introduction to Bayesian Optimization (7-8 courses)"),r.a.createElement("p",null,r.a.createElement("strong",null,"Dates"),". 20 Oct 2023 \u2014 12 or 14 Nov 2023."),r.a.createElement("p",null,r.a.createElement("strong",null,"Class format"),". I will give lectures on foundational material. There will be assigned readings from the ",e,", which should ideally be completed before each class.  I trust that you will complete the readings on whatever timeline supports your schedule and learning style.  Please note that if you fall behind in the readings you may have trouble engaging with the research papers covered in the second half of the course."),r.a.createElement("p",null,r.a.createElement("strong",null,"Assignments"),". Beyond readings, there will also be (1) the ",r.a.createElement(O,{inside:!0,href:"#diagnostic-pset"},"diagnostic problem set")," and (2) a ",r.a.createElement(O,{inside:!0,href:"#short-coding-exercise"},"short coding exercise"),". Additionally, those of you choosing the ",r.a.createElement(O,{inside:!0,href:"#research-project"},"research project option")," for final assessment will submit your project proposal."),r.a.createElement("p",{id:"part1-topics"},r.a.createElement("strong",null,"Topics")," will include:"),r.a.createElement("ol",null,r.a.createElement("li",null,"Introduction to blackbox/Bayesian optimization (1 class)"),r.a.createElement("li",null,"Gaussian processes as surrogate models (2 classes)"),r.a.createElement("li",null,"Bayesian decision and optimization theory (1 class)"),r.a.createElement("li",null,"Acquisition functions (1 class)"),r.a.createElement("li",null,"Computational considerations (1 class)"),r.a.createElement("li",null,"Introduction to bandits/Bayesian optimization theory (1 class)")),r.a.createElement(j,null,"Part 2: Current Topics in Bayesian Optimization Research (6-7 courses)"),r.a.createElement("p",null,r.a.createElement("strong",null,"Dates"),". 14 or 19 Nov 2023 \u2014 7 Dec 2023."),r.a.createElement("p",null,r.a.createElement("strong",null,"Class format"),". For the second half of the course, the classroom will be flipped. We will be discussing 1-2 current research papers each class. Each student (who isn't choosing the ",r.a.createElement(O,{inside:!0,href:"#research-project"},"research project option")," for their final assessment) will be responsible for leading at least one of the topics classes. The class will consist of 30-minute presentations on one of the papers, followed by 15 minute discussions. (See ",r.a.createElement(O,{inside:!0,href:"#topics-presentation"},"above")," for more details.)"),r.a.createElement("p",null,r.a.createElement("small",null,"(Details and scheduling for this portion of the class will be ironed out after everyone chooses their final assessment preference.)")),r.a.createElement("p",null,r.a.createElement("strong",null,"Assignments"),". For the students who aren't leading a particular class, you will be responsible for reading the papers before the class starts. Furthermore, you will also have to ",r.a.createElement(O,{inside:!0,href:"#topics-presentation-deliverables"},"write a conference/journal-style review")," of at least one of the papers presented each class. (Students who choose the research project option will be exempt from writing reviews.)"),r.a.createElement("p",{id:"part2-topics"},r.a.createElement("strong",null,"Topics")," will include:"),r.a.createElement("ul",null,r.a.createElement("li",null,"Local/high dimensional optimization"),r.a.createElement("li",null,"Latent space/generative model-based optimization"),r.a.createElement("li",null,"Mixed-space optimization"),r.a.createElement("li",null,"Multi-objective optimization"),r.a.createElement("li",null,"Constrained optimization"),r.a.createElement("li",null,"Preference learning"),r.a.createElement("li",null,"Non-myopic decision making"),r.a.createElement("li",null,"Cost aware Bayesian optimization"),r.a.createElement("li",null,'"Greybox" optimization'),r.a.createElement("li",null,"Generalizations of Bayesian optimization")),r.a.createElement("p",null,"Specific paper recommendations for each topic will be posted soon!")),r.a.createElement(R,{id:"assessment"},r.a.createElement(M,null,"Assessment"),r.a.createElement(f.n,{striped:!0,hover:!0},r.a.createElement("thead",null,r.a.createElement("tr",null,r.a.createElement("th",null,"Category"),r.a.createElement("th",null,"Contribution"),r.a.createElement("th",null,"Notes"))),r.a.createElement("tbody",null,r.a.createElement("tr",null,r.a.createElement("td",null,"Class participation"),r.a.createElement("td",null,"5%"),r.a.createElement("td",null)),r.a.createElement("tr",null,r.a.createElement("td",null,r.a.createElement(O,{inside:!0,href:"#diagnostic-pset"},"Diagnostic problem set")),r.a.createElement("td",null,"15%"),r.a.createElement("td",null,"See description above.")),r.a.createElement("tr",null,r.a.createElement("td",null,r.a.createElement(O,{inside:!0,href:"#short-coding-exercise"},"Short coding exercise")),r.a.createElement("td",null,"20%"),r.a.createElement("td",null,"See description above.")),r.a.createElement("tr",null,r.a.createElement("td",null,r.a.createElement(O,{inside:!0,href:"#final-assessment"},"Final assessment")),r.a.createElement("td",null,"60%"),r.a.createElement("td",null,"See description above. Specific grading breakdown TBD.")))),r.a.createElement("p",null,"Rubrics will be released before each assignment is due."),r.a.createElement(j,null,"Concessions"),r.a.createElement("p",null,"Please ",a," as soon as possible if you will have trouble completing an assignment on time and/or participating in class. I understand the effects of life events, health circumstances (mental or physical), and scheduling, and I will work with you to best structure your learning/assessment. Please also refer to ",r.a.createElement(O,{href:"https://vancouver.calendar.ubc.ca/campus-wide-policies-and-regulations/academic-concession"},"UBC's policies on academic concession."),".")),r.a.createElement(R,null,r.a.createElement(M,null,"Resources"),r.a.createElement(j,{id:"textbook"},"Primary Textbook"),r.a.createElement("p",null,"We will be following the brand-new textbook ",r.a.createElement(O,{href:"https://bayesoptbook.com#download"},"Bayesian Optimization")," written by ",r.a.createElement(O,{href:"https://www.cse.wustl.edu/~garnett/"},"Roman Garnett"),". It is available as a free PDF online, or (for those of you who are old-school) available as a hardcover book from ",r.a.createElement(O,{href:"https://www.amazon.ca/Bayesian-Optimization-Roman-Garnett/dp/110842578X"},"Amazon"),"."),r.a.createElement(j,{id:"canvas"},"Canvas"),r.a.createElement("p",{id:"course-canvas"},"We will use ",t," for 1) announcements, 2) discussions, and 3) uploading assignments. Please post all non-personal questions as a discussion\u2014your fellow classmates might be able to answer them for you!"),r.a.createElement(j,null,"Demonstrations"),r.a.createElement("p",null,"I will occasionally present small toy demonstrations during class. They will be made available on ",r.a.createElement(O,{href:"https://github.com/gpleiss/gp_bo_demos/"},"this Github repository"),"."),r.a.createElement(j,{id:"textbook"},"Optional References"),r.a.createElement("ul",null,r.a.createElement("li",null,r.a.createElement(la,{authors:"C. E. Rasmussen, C. Williams",link:"https://gaussianprocess.org/gpml/chapters/",title:"Gaussian processes for machine learning",venue:"MIT Press",year:"2006",book:!0})),r.a.createElement("li",null,r.a.createElement(la,{authors:"A. Gelman, J. Carlin, H. Stern, D. Dunson, A. Vehtari, D. Rubin",link:"http://www.stat.columbia.edu/~gelman/book/BDA3.pdf",title:"Bayesian data analysis, 3rd edition",venue:"CRC Press",year:"2013",book:!0})),r.a.createElement("li",null,"Helpful review papers, including:",r.a.createElement("ul",null,r.a.createElement("li",null,r.a.createElement(la,{authors:"P. I. Frazier",link:"https://arxiv.org/pdf/1807.02811.pdf",title:"A Tutorial on Bayesian Optimization",year:2018})),r.a.createElement("li",null,r.a.createElement(la,{authors:"J. Snoek, H. Larochelle, R. P. Adams",link:"https://arxiv.org/pdf/1206.2944.pdf",title:"Practical Bayesian optimization of machine learning algorithms",venue:"NeurIPS",year:2012})),r.a.createElement("li",null,r.a.createElement(la,{authors:"B. Shahriari, K. Swersky, Z. Wang, R. P. Adams, N. De~Freitas",link:"https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf",title:"Taking the human out of the loop: A review of Bayesian optimization",year:2015})),r.a.createElement("li",null,r.a.createElement(la,{authors:"I. Dewancker, M. McCourt, S. Clark.",link:"https://static.sigopt.com/b/20a144d208ef255d3b981ce419667ec25d8412e2/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf",title:"Bayesian optimization primer",year:2015})))),r.a.createElement("li",null,r.a.createElement(O,{href:"https://ax.dev"},"AX")," and ",r.a.createElement(O,{href:"https://botorch.org"},"BoTorch")," software libraries."))),r.a.createElement(R,null,r.a.createElement(M,null,"Policies and Values"),r.a.createElement("p",null,"UBC provides resources to support student learning and to maintain healthy lifestyles but recognizes that sometimes crises arise and so there are additional resources to access including those for survivors of sexual violence. UBC values respect for the person and ideas of all members of the academic community. Harassment and discrimination are not tolerated nor is suppression of academic freedom. UBC provides appropriate accommodation for students with disabilities and for religious, spiritual and cultural observances. UBC values academic honesty and students are expected to acknowledge the ideas generated by others and to uphold the highest academic standards in all of their actions. Details of the policies and how to access support are available ",r.a.createElement(O,{href:"http://senate.ubc.ca/policies-resources-support-student-success"},"here"),".")))}}]),a}(r.a.Component),sa=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){var e=this.props.venue?this.props.venue+", "+this.props.year:"ArXiV, "+this.props.year,t="";this.props.children&&(t=r.a.createElement("p",{className:"font-italic text-secondary"},"(",this.props.children,")"));var a=this.props.taken?r.a.createElement("del",null,this.props.title):r.a.createElement(O,{href:this.props.link},this.props.title),n="mb-3";return this.props.taken&&(n+=" text-secondary"),r.a.createElement("li",{className:n},a,r.a.createElement("br",null),r.a.createElement("span",null,this.props.authors),r.a.createElement("br",null),r.a.createElement("span",null,e),r.a.createElement("br",null),r.a.createElement("strong",null,"Topics:")," ",this.props.topics,r.a.createElement("br",null),r.a.createElement("strong",null,"Style:")," ",this.props.styl,t)}}]),a}(r.a.Component),oa=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(){return Object(i.a)(this,a),t.apply(this,arguments)}return Object(s.a)(a,[{key:"render",value:function(){return r.a.createElement("div",null,r.a.createElement("div",{className:"bg-gradient-primary pt-10 pb-5 shadow-bottom"},r.a.createElement("div",{className:"container text-center"},r.a.createElement(I,null,"STAT548 PhD Qualifying Course Papers"))),r.a.createElement("div",{className:"container"},r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-sm-12"},r.a.createElement(R,null,r.a.createElement("div",null,r.a.createElement("strong",null,"Published:")," 6 August 2024",r.a.createElement("br",null),r.a.createElement("strong",null,"Last Updated:")," ","6 August 2024")))),r.a.createElement("div",{className:"row"},r.a.createElement("div",{className:"col-sm-12"},r.a.createElement(R,null,r.a.createElement("p",null,'If you are interested in a qualifying paper with me, please email me to schedule a one-on-one meeting. The subject line of your email should start with "[Qualifying Paper]" to ensure I don\'t accidentally miss it. Come to the meeting prepared to discuss:'),r.a.createElement("ul",null,r.a.createElement("li",null,"your background,"),r.a.createElement("li",null,"your long-term research interests (it's okay if these are not yet well-defined),"),r.a.createElement("li",null,"the specific paper you are interested in and the reasons for your interest,"),r.a.createElement("li",null,"your planned submission date for your report (typically 4-6 weeks after we meet), and"),r.a.createElement("li",null,"initial ideas for a mini-project based on the paper.")),r.a.createElement("p",null,"To ensure a productive meeting, please spend some time reviewing the paper before we meet."))),r.a.createElement("div",{className:"col-sm-12"},r.a.createElement(R,null,r.a.createElement(M,null,"What to Expect From Me as a Supervisor"),r.a.createElement("p",null,"The qualifying papers I've listed below are representative of my current research interests: Bayesian optimization and neural network uncertainty quantification. More specifically, I'm interested in heuristic and approximate notions of uncertainty from machine learning models, and how they can inform reliable and optimal downstream decisions within the contexts of experimental design and scientific discovery.")),r.a.createElement(R,null,r.a.createElement(M,null,"Timeline and Deliverables"),r.a.createElement("p",null,"The final report for your qualifying paper will comprise two parts: (1) an extended review demonstrating your comprehension and critical evaluation of the paper, and (2) a mini-research project. Part 1 (the extended review) should take 2-3 weeks, and Part 2 (the project) should take 3-4 weeks."),r.a.createElement(j,null,"Part 1: The Extended Review"),r.a.createElement("p",null,"The extended review should be divided into two sections:"),r.a.createElement("ol",null,r.a.createElement("li",{className:"mb-3"},r.a.createElement("strong",null,"Technical/methodological summary (roughly 3 pages)"),r.a.createElement("br",null),r.a.createElement("p",null,"This section should exhibit your grasp of the paper's technical content. Expect to review some related literature, as you should be able to contextualize the paper within the broader subfield. Address the following prompts in your summary:"),r.a.createElement("ul",null,r.a.createElement("li",null,r.a.createElement("em",null,"Theory papers:")," Provide a concise overview of primary technical outcomes and major proof techniques. Explain assumptions and their rationale. Relate to existing results and potential relaxations. Highlight innovative proof techniques."),r.a.createElement("li",null,r.a.createElement("em",null,"Methodological/applied papers:")," Explain the proposed methodology and its theoretical properties. Discuss computational complexity. Identify crucial aspects and potential bottlenecks. Mention alternative methods that could also be appplied to the given problem."))),r.a.createElement("li",{className:"mb-3"},r.a.createElement("strong",null,"Mini-project proposal (roughly 1-2 pages)"),r.a.createElement("br",null),r.a.createElement("p",null,"This section should demonstrate your ability to think creatively about research. Brainstorm a generalization, extension, or novel application of the paper's content. Dreaming too big is better than dreaming too small: aim for a project with potential for publication or inclusion in your thesis. (I'll help you scope whatever you come up with into a 3-4 week mini-project.)"),r.a.createElement("p",null,"Your proposal should (1) describe the area of opportunity, (2) propose a method/approach, (3) identify expected technical challenges/bottlenecks, and (4) predict potential impact."))),r.a.createElement(j,null,"Part 2: The (Mini) Project"),r.a.createElement("p",null,"After completing a draft of your extended review, we'll meet one-on-one to define a 3-4 week project based on your proposal. You will turn in a 4+ page report along with associated code and data. The content of the project will depend on the style of the paper"),r.a.createElement("ul",null,r.a.createElement("li",null,r.a.createElement("em",null,"Theory papers:")," If you choose a paper that is purely theoretical in nature, I will expect a predominantly mathematical project (extending the paper's theorems to a novel setting, apply the paper's proof techniques to a different problem, etc)."),r.a.createElement("li",null,r.a.createElement("em",null,"Methodological/applied papers:")," Expect a mix of theory and coding, as well as getting your hands dirty with some real-world data.  (If you want to use a language other than Python, you will need a really convincing argument!)")),r.a.createElement("p",null,r.a.createElement("strong",null,"Workflow expectations:")," My research approach tends to be highgly iterative, and I anticipate the same for our mini-projects. Initial project ideas will likely require modification to be fruitful. Be prepared to pivot or adjust your project, perhaps more than once."),r.a.createElement("p",null,'In my opinion, a good researcher knows when to "fail fast." Most research ideas don\'t work, so figure out the fastest way to evaluate whether your ideas are likely to be dead ends. Design a minimal experiment/derivation for quick evaluation. If results seem promising in a week or two, continue pursuing the idea. Otherwise, adapt or pivot.'),r.a.createElement("p",null,"I expect you to check in with me at least once (ideally more) over the course of your project. Share (1) early results indicating your approach's viability and (2) your plan to pivot or adapt based on those results. Slack communication is preferred, but I'm always happy to meet in person if you want to bounce ideas off of each other."),r.a.createElement("p",null,r.a.createElement("strong",null,"Formatting:")," Submit the report as a GitHub repository, using the template at ",r.a.createElement(O,{href:"https://github.com/ben-br/qp-template/"},"https://github.com/ben-br/qp-template/"),".  The template includes a LATEX style file that should be used for the report. (Detailed instructions for usage can be found in the repository\u2019s README file.) Ensure that the experimental results are reproducible. Write reusable/documented/well-commented Python code, and publish the code in a GitHub repo that I have access to. I should easily install and run your experiments.")),r.a.createElement(R,null,r.a.createElement(M,null,"What I am Looking For"),r.a.createElement(j,null,"Official Assessment"),r.a.createElement("p",null,"As outlined in the ",r.a.createElement(O,{href:"https://www.stat.ubc.ca/sites/default/files/reportcard.pdf"},"assessment form"),', your evaluation will be based on: (1) your overall comprehension, (2) your ability to "go beyond," and (3) your work habits/reporting/communication skills. The extended review should showcase your understanding, while the mini-research project should demonstrate your creative thinking and ability to "go beyond."'),r.a.createElement(j,null,"Unofficial Assessment"),r.a.createElement("p",null,"The qualifying paper also gives me the chance to gauge your research potential and our compatibility in a mentor-mentee dynamic. I will not judge you based on how good your project results are. Rather, I will evaluate you on the following:"),r.a.createElement("ul",null,r.a.createElement("li",null,"shared research interests,"),r.a.createElement("li",null,"strong technical proficiency (or an ability to quickly acquire new skills),"),r.a.createElement("li",null,'capacity to "fail fast" (as described in the project details),'),r.a.createElement("li",null,"independence and proactivity,"),r.a.createElement("li",null,"effective communication of when assistance is needed,"),r.a.createElement("li",null,"receptiveness to feedback, and"),r.a.createElement("li",null,"awareness of the societal and ethical implications of machine learning research."))),r.a.createElement(R,null,r.a.createElement(M,null,"Qualifying Papers (updated ","6 August 2024",")"),r.a.createElement("p",null,"If a paper is crossed out, then it is no longer available."),r.a.createElement("ol",null,r.a.createElement(sa,{title:"Discovering Many Diverse Solutions with Bayesian Optimization",authors:"N. Maus, K. Wu, D. Eriksson, J.R. Gardner",venue:"AISTATS",year:"2023",link:"https://arxiv.org/abs/2210.10953",topics:"Bayesian optimization, molecule generation",styl:"Applied, methodological"}),r.a.createElement(sa,{title:"Bayesian Optimization of Function Networks with Partial Evaluations",authors:"P. Buathong, J. Wan, R. Astudillo, S. Daulton, M. Balandat, P.I. Frazier",venue:"ICML",year:"2024",link:"https://arxiv.org/abs/2311.02146",topics:"Bayesian optimization, molecule generation",styl:"Methodological, applied"}),r.a.createElement(sa,{title:"The Behavior and Convergence of Local Bayesian Optimization",authors:"K. Wu, K. Kim, R. Garnett, J.R. Gardner",venue:"NeurIPS",year:"2023",link:"https://arxiv.org/abs/2305.15572",topics:"Bayesian optimization",styl:"Theoretical"}),r.a.createElement(sa,{title:"Active Statistical Inference",authors:"T. Zrnic, E.J. Cand\xe8s",venue:"ICML",year:"2024",link:"https://arxiv.org/abs/2403.03208",topics:"Uncertainty quantification, neural networks, conformal prediction",styl:"Methodological, theoretical"}),r.a.createElement(sa,{title:"Is In-Context Learning in Large Language Models Bayesian? A Martingale Perspective",authors:"F. Falck, Z. Wang, C. Holmes",venue:"ICML",year:"2024",link:"https://arxiv.org/abs/2406.00793",topics:"Uncertainty quantification, LLMs, Bayesian inference",styl:"Theoretical"}))),r.a.createElement(R,null,r.a.createElement(M,null,"Useful Resources/Advice"),r.a.createElement("p",null,"Many of these links have been shared by other faculty members as well:"),r.a.createElement("ul",null,r.a.createElement("li",null,"Nancy Heckman's ",r.a.createElement(O,{href:"http://ugrad.stat.ubc.ca/~nancy/writing/"},"page on technical writing,")),r.a.createElement("li",null,"Harry Joe's ",r.a.createElement(O,{href:"http://www.stat.ubc.ca/~harry/papers/"},"page on mathematical writing and typesetting in LaTeX,")),r.a.createElement("li",null,"Trevor Campbell's ",r.a.createElement(O,{href:"https://docs.google.com/presentation/d/13vwchlzQAZjjfiI3AiBC_kM-syI6GJKzbuZoLxgy1a4/edit"},'talk on "How to Explain Things,"')),r.a.createElement("li",null,"Knuth, Larrabee, and Roberts ",r.a.createElement(O,{href:"http://www.jmlr.org/reviewing-papers/knuth_mathematical_writing.pdf"},"on mathematical writing,")),r.a.createElement("li",null,'"Getting Started with Git": ',r.a.createElement(O,{href:"https://git-scm.com/book/en/v2"},"Chapters 1 and 2"),", and"),r.a.createElement("li",null,"my ",r.a.createElement(O,{href:"../../git_wizard.pdf"},'talk on "How to Be a Git Wizard"')," (if git still scares you after reading the above resource)."))),r.a.createElement(R,null,r.a.createElement("p",null,r.a.createElement("small",null,"Many parts of this document were derived/adapted/copied from Ben, Trevor, Marie, and Daniel. Thanks all!")))))))}}]),a}(r.a.Component),ca=(a(287),a(82)),ma=a.n(ca),ua=function(e){Object(c.a)(a,e);var t=Object(m.a)(a);function a(e){var n;return Object(i.a)(this,a),(n=t.call(this,e)).toggleNavbar=n.toggleNavbar.bind(Object(o.a)(n)),n.state={isNavbarOpen:!1},n}return Object(s.a)(a,[{key:"toggleNavbar",value:function(){this.setState({isNavbarOpen:!this.state.isNavbarOpen})}},{key:"render",value:function(){var e=Object(u.b)([{path:"/",element:r.a.createElement(p.b,null),children:[{index:!0,element:r.a.createElement(q,null)},{path:"index.html",element:r.a.createElement(p.a,{to:"/"})},{path:"prospective_member.html",element:r.a.createElement(Y,null)},{path:"blog",element:r.a.createElement(p.b,null),children:[{path:"aum.html",element:r.a.createElement(bt,null)},{path:"nn_calibration.html",element:r.a.createElement(pe,null)}]},{path:"bio.html",element:r.a.createElement(At,null)},{path:"research",element:r.a.createElement(p.b,null),children:[{index:!0,element:r.a.createElement(kt,null)},{path:"index.html",element:r.a.createElement(p.a,{to:"/research/"})}]},{path:"teaching",element:r.a.createElement(p.b,null),children:[{path:"stat548",element:r.a.createElement(p.b,null),children:[{index:!0,element:r.a.createElement(oa,null)},{path:"index.html",element:r.a.createElement(p.a,{to:"/teaching/stat548/"})}]},{path:"stat547u",element:r.a.createElement(Tt,null),children:[{index:!0,element:r.a.createElement(_t,null)},{path:"index.html",element:r.a.createElement(p.a,{to:"/teaching/stat547u/"})},{path:"syllabus.html",element:r.a.createElement(qt,null)},{path:"final.html",element:r.a.createElement(Kt,null)}]},{path:"stat520p",element:r.a.createElement(Qt,null),children:[{index:!0,element:r.a.createElement(aa,null)},{path:"index.html",element:r.a.createElement(p.a,{to:"/teaching/stat520p/"})},{path:"syllabus.html",element:r.a.createElement(ia,null)},{path:"papers.html",element:r.a.createElement(ra,null)}]}]}],errorElement:r.a.createElement(Q,null)}]);return r.a.createElement("div",null,r.a.createElement("div",{id:"app"},r.a.createElement(f.k,{color:"dark",dark:!0,expand:"lg"},r.a.createElement(f.l,{className:"m-0 mr-md-4 ml-md-4 link-unstyled small-caps h3",href:"/"},"Geoff Pleiss"),r.a.createElement(f.m,{onClick:this.toggleNavbar}),r.a.createElement(f.a,{isOpen:this.state.isNavbarOpen,navbar:!0},r.a.createElement(f.h,{className:"mr-auto ml-md-4",navbar:!0},r.a.createElement(f.p,{nav:!0,inNavbar:!0},r.a.createElement(f.d,{nav:!0,caret:!0,href:"/research/"},"Research"),r.a.createElement(f.c,null,r.a.createElement(f.b,{href:"/research/"},"Overview"),r.a.createElement("div",{className:"dropdown-divider"}),r.a.createElement(f.b,{href:"/research/#uq"},"Uncertainty Quantification"),r.a.createElement(f.b,{href:"/research/#bo"},"Bayesian Optimization"),r.a.createElement(f.b,{href:"/research/#reliable-nn"},"Deep Learning"),r.a.createElement(f.b,{href:"/research/#nla"},"Scalable Gaussian Processes via Numerical Methods"),r.a.createElement(f.b,{href:"/research/#spatiotemporal"},"Spatiotemporal Modeling"),r.a.createElement(f.b,{href:"/research/#prob-modeling"},"Probabilistic Modeling"),r.a.createElement(f.b,{href:"/research/#cv"},"Computer Vision"))),r.a.createElement(f.p,{nav:!0,inNavbar:!0},r.a.createElement(f.d,{nav:!0,caret:!0,href:"/teaching/"},"Teaching"),r.a.createElement(f.c,null,r.a.createElement(f.b,{href:"/teaching/stat547u/"},"(2025) STAT 547U (Topics in Deep Learning Theory)"),r.a.createElement(f.b,{href:"https://ubc-stat.github.io/stat-406/"},"(2024) STAT 406 (Methods for Statistical Learning)"),r.a.createElement(f.b,{href:"/teaching/stat520p/"},"(2023) STAT 520P (Bayesian Optimization)"),r.a.createElement(f.b,{href:"/teaching/stat548/"},"STAT 548 (PhD Qualifying Course)"))),r.a.createElement(f.p,{nav:!0,inNavbar:!0},r.a.createElement(f.d,{nav:!0,caret:!0},"Open Source"),r.a.createElement(f.c,null,r.a.createElement(f.b,{href:"https://gpytorch.ai",target:"_blank"},"GPyTorch"),r.a.createElement(f.b,{href:"https://linear-operator.readthedocs.io",target:"_blank"},"LinearOperator"))),r.a.createElement(f.p,{nav:!0,inNavbar:!0},r.a.createElement(f.d,{nav:!0,caret:!0},"Blog"),r.a.createElement(f.c,null,r.a.createElement(f.b,{href:"/blog/nn_calibration.html"},"Neural Network Calibration"),r.a.createElement(f.b,{href:"/blog/aum.html"},"Area Under the Margin (AUM)"))),r.a.createElement(f.i,null,r.a.createElement(f.j,{href:"/geoffpleiss_cv.pdf",target:"_blank"},"CV")),r.a.createElement(f.i,null,r.a.createElement(f.j,{href:"/bio.html"},"Bio")),r.a.createElement(f.i,{className:"d-inline d-lg-none"},r.a.createElement(f.j,{href:"https://scholar.google.com/citations?user=XO8T-Y4AAAAJ&hl=en&oi=ao",target:"_blank"},"Google Scholar")),r.a.createElement(f.i,{className:"d-inline d-lg-none"},r.a.createElement(f.j,{href:"http://github.com/gpleiss",target:"_blank"},"Github")))),r.a.createElement(f.h,{navbar:!0,className:"mr-lg-4 ml-lg-4 d-none d-lg-flex","aria-hidden":"true"},r.a.createElement(f.i,{className:"ml-3"},r.a.createElement(f.j,{className:"text-white",href:"https://scholar.google.com/citations?user=XO8T-Y4AAAAJ&hl=en&oi=ao",target:"_blank"},r.a.createElement("img",{src:ma.a,style:{width:"36px"},alt:"Google Scholar"}))),r.a.createElement(f.i,{className:"ml-3"},r.a.createElement(f.j,{className:"text-white",href:"http://github.com/gpleiss",target:"_blank"},r.a.createElement(d.a,{icon:g.a,size:"2x",title:"Github"})))))),r.a.createElement(p.d,{router:e}))}}]),a}(r.a.Component);Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()})),Object(l.render)(r.a.createElement(ua,null),document.getElementById("root"))},34:function(e,t,a){e.exports=a.p+"static/media/me.0c3be0b6.jpg"},37:function(e,t,a){e.exports=a.p+"static/media/cifar_uncal.eed183f7.png"},38:function(e,t,a){e.exports=a.p+"static/media/cifar_temp.8c566b45.png"},39:function(e,t,a){e.exports=a.p+"static/media/averaged_trajectories_clean.d1e0f3f2.png"},40:function(e,t,a){e.exports=a.p+"static/media/averaged_trajectories_mislabeled.f16b9d8d.png"},41:function(e,t,a){e.exports=a.p+"static/media/mnist.4cb9b0a5.png"},42:function(e,t,a){e.exports=a.p+"static/media/imagenet1.90666ccb.png"},43:function(e,t,a){e.exports=a.p+"static/media/imagenet2.4607c876.png"},44:function(e,t,a){e.exports=a.p+"static/media/imagenet3.df4f16c1.png"},45:function(e,t,a){e.exports=a.p+"static/media/imagenet4.2a1f7932.png"},46:function(e,t,a){e.exports=a.p+"static/media/imagenet5.19eb40ec.png"},47:function(e,t,a){e.exports=a.p+"static/media/imagenet6.ba3be719.png"},48:function(e,t,a){e.exports=a.p+"static/media/imagenet7.e8009a7f.png"},49:function(e,t,a){e.exports=a.p+"static/media/imagenet8.1396e7e6.png"},50:function(e,t,a){e.exports=a.p+"static/media/cifar1.7d34c260.png"},51:function(e,t,a){e.exports=a.p+"static/media/cifar2.f8549a14.png"},52:function(e,t,a){e.exports=a.p+"static/media/cifar3.781af702.png"},53:function(e,t,a){e.exports=a.p+"static/media/cifar4.1b9aabd1.png"},54:function(e,t,a){e.exports=a.p+"static/media/cifar5.ee9c2a15.png"},55:function(e,t,a){e.exports=a.p+"static/media/cifar6.42304f64.png"},56:function(e,t,a){e.exports=a.p+"static/media/cifar7.214fe072.png"},57:function(e,t,a){e.exports=a.p+"static/media/cifar8.bfcd5763.png"},58:function(e,t,a){e.exports=a.p+"static/media/webvision1.1b88f3e8.png"},59:function(e,t,a){e.exports=a.p+"static/media/webvision2.32099f40.png"},60:function(e,t,a){e.exports=a.p+"static/media/webvision3.41fc1c20.png"},61:function(e,t,a){e.exports=a.p+"static/media/webvision4.a8efd053.png"},62:function(e,t,a){e.exports=a.p+"static/media/webvision5.f49c48af.png"},63:function(e,t,a){e.exports=a.p+"static/media/webvision6.576fcdd7.png"},64:function(e,t,a){e.exports=a.p+"static/media/webvision7.6850bcfe.png"},65:function(e,t,a){e.exports=a.p+"static/media/webvision8.6add5996.png"},66:function(e,t,a){e.exports=a.p+"static/media/cifar10_high_aum.1d188306.csv"},67:function(e,t,a){e.exports=a.p+"static/media/cifar100_high_aum.cf8272e5.csv"},68:function(e,t,a){e.exports=a.p+"static/media/DenseNet_Journal.8791eef8.pdf"},69:function(e,t,a){e.exports=a.p+"static/media/Hydrometeorology_Journal.f6acb318.pdf"},70:function(e,t,a){e.exports=a.p+"static/media/gpleiss_thesis.d218bc00.pdf"},71:function(e){e.exports=JSON.parse('[{"type":"section","topic":"Part 0: Introduction","assignment":"assignment1"},{"type":"class","topic":"Course logistics, introduction, failures of classical learning theory","lectureNotes":"introLecture"},{"type":"class","topic":"Introduction to functional analysis, reproducing kernel Hilbert spaces","lectureNotes":"rkhsLecture"},{"type":"class","topic":"Double descent, implicit bias of gradient descent for regression","readingTitle":"Fit Without Fear (Sections 1-3.9)","readingAuthorYear":"Belkin, 2021","readingUrl":"https://arxiv.org/abs/2105.14368","note":"Required reading, but no reading summary due.","lectureNotes":"doubleDescentLecture"},{"type":"section","topic":"Part 1: Overparameterized linear regression"},{"type":"class","topic":"Introduction to high-dimensional asymptotics and random matrix theory","readingTitle":"High Dimensional Regression (Section 2)","readingAuthorYear":"Hastie, 2023","readingUrl":"https://www.stat.berkeley.edu/~ryantibs/statlearn-s23/lectures/ridge.pdf","lectureNotes":"rmtLecture","links":[{"name":"Demo","url":"https://colab.research.google.com/drive/1-9EfwXkcQTvxTz_GbzCrG6uK7Q_WUcjn?usp=sharing"}]},{"type":"class","topic":"Effective regularization, risk of overparameterized ridge regression","readingTitle":"High Dimensional Regression (Section 4)","readingAuthorYear":"Hastie, 2023","readingUrl":"https://www.stat.berkeley.edu/~ryantibs/statlearn-s23/lectures/ridge.pdf","lectureNotes":"implicitRegLecture"},{"type":"class","topic":"Benign overfitting","readingTitle":"Benign, Tempered, or Catastrophic: A Taxonomy of Overfitting (Section 2-3)","readingAuthorYear":"Mallinar et al., 2022","readingUrl":"https://arxiv.org/abs/2207.06569"},{"type":"section","topic":"Part 2: Approximating neural networks as kernel machines","assignment":"assignment2"},{"type":"class","topic":"Infinite width NNs: Neural Tangent Kernel (Pt 1)","readingTitle":"Deep Learning Theory Lecture Notes (Ch. 4)","readingAuthorYear":"Telgarsky, 2021","readingUrl":"https://mjt.cs.illinois.edu/dlt/#approximation-near-initialization-and-the-neural-tangent-kernel"},{"type":"class","topic":"Infinite width NNs: Neural Tangent Kernel (Pt 2)","readingTitle":"Understanding the Neural Tangent Kernel","readingAuthorYear":"Dwaraknath, 2019","readingUrl":"https://www.eigentales.com/NTK/"},{"type":"class","topic":"Feature learning, rich vs lazy regimes","readingTitle":"The lazy (NTK) and rich (\xb5P) regimes: A gentle tutorial","readingAuthorYear":"Karkada, 2024","readingUrl":"https://arxiv.org/pdf/2404.19719","note":"Optional reading; no reading summary due."},{"type":"section","topic":"Part 3: Advanced topics"},{"type":"class","topic":"Neural networks for classification","readingTitle":"Deep Learning Theory Lecture Notes (Ch. 10)","readingAuthorYear":"Telgarsky, 2021","readingUrl":"https://mjt.cs.illinois.edu/dlt/#sec:margin_opt"},{"type":"class","topic":"Effects of depth"},{"type":"class","topic":"Topic TBD (scaling laws, in-context learning, etc.)"},{"type":"section","topic":"Feb 14: oral presentations for final paper reading assignment"}]')},72:function(e,t,a){e.exports=a.p+"static/media/stat547u_lecture01.4aee32b9.pdf"},73:function(e,t,a){e.exports=a.p+"static/media/stat547u_lecture02.6ce8c832.pdf"},74:function(e,t,a){e.exports=a.p+"static/media/stat547u_lecture03.53e954a6.pdf"},75:function(e,t,a){e.exports=a.p+"static/media/stat547u_lecture04.2af15a85.pdf"},76:function(e,t,a){e.exports=a.p+"static/media/stat547u_lecture05.12f58a12.pdf"},77:function(e,t,a){e.exports=a.p+"static/media/stat547u_pset01_instructions.b225090d.pdf"},78:function(e,t,a){e.exports=a.p+"static/media/stat547u_pset01_template.4f1350ca.tex"},79:function(e,t,a){e.exports=a.p+"static/media/stat520p_pset1.60818d1b.pdf"},80:function(e,t,a){e.exports=a.p+"static/media/stat520p_pset1.83ad06d5.tex"},81:function(e){e.exports=JSON.parse('[{"Paper":"High-Dimensional Bayesian Optimisation with Variational Autoencoders and Deep Metric Learning","Tags":"latent space BO","Date":2021,"URL":"https://arxiv.org/abs/2106.03609","Venue":"","Authors":"Antoine Grosnit, Rasul Tutunov, Alexandre Max Maraval, Ryan-Rhys Griffiths, Alexander I. Cowen-Rivers, Lin Yang, Lin Zhu, Wenlong Lyu, Zhitang Chen, Jun Wang, Jan Peters, Haitham Bou-Ammar"},{"Paper":"Combining Latent Space and Structured Kernels for Bayesian Optimization over Combinatorial Spaces","Tags":"latent space BO","Date":2021,"URL":"https://arxiv.org/abs/2111.01186","Venue":"NeurIPS","Authors":"Aryan Deshwal, Janardhan Rao Doppa"},{"Paper":"Local Latent Space Bayesian Optimization over Structured Inputs","Tags":"latent space BO, local BO","Date":2023,"URL":"https://arxiv.org/abs/2201.11872","Venue":"NeurIPS","Authors":"Natalie Maus, Haydn T. Jones, Juston S. Moore, Matt J. Kusner, John Bradshaw, Jacob R. Gardner"},{"Paper":"Accelerating Bayesian Optimization for Biological Sequence Design with Denoising Autoencoders","Tags":"latent space BO","Date":2023,"URL":"https://arxiv.org/abs/2203.12742","Venue":"ICML","Authors":"Samuel Stanton, Wesley Maddox, Nate Gruver, Phillip Maffettone, Emily Delaney, Peyton Greenside, Andrew Gordon Wilson"},{"Paper":"Scalable Global Optimization via Local Bayesian","Tags":"local BO","Date":2019,"URL":"https://arxiv.org/abs/1910.01739","Venue":"NeurIPS","Authors":"David Eriksson, Michael Pearce, Jacob R Gardner, Ryan Turner, Matthias Poloczek"},{"Paper":"Discovering Many Diverse Solutions with Bayesian Optimization\\n","Tags":"latent space BO, local BO, misspecified BO","Date":2023,"URL":"https://arxiv.org/abs/2210.10953","Venue":"AISTATS","Authors":"Natalie Maus, Kaiwen Wu, David Eriksson, Jacob R. Gardner"},{"Paper":"The Behavior and Convergence of\\nLocal Bayesian Optimization\\n","Tags":"local BO","Date":2023,"URL":"https://arxiv.org/abs/2305.15572","Venue":"NeurIPS","Authors":"Kaiwen Wu, Kyurae Kim, Roman Garnett, Jacob R. Gardner"},{"Paper":"Deep Gaussian Processes for Multi-fidelity Modeling","Tags":"greybox BO","Date":2019,"URL":"https://arxiv.org/abs/1903.07320","Venue":"","Authors":"Kurt Cutajar, Mark Pullin, Andreas Damianou, Neil Lawrence, Javier Gonz\xe1lez"},{"Paper":"Bayesian Optimization of Function Networks","Tags":"greybox BO","Date":2021,"URL":"https://arxiv.org/abs/2112.15311","Venue":"NeurIPS","Authors":"Raul Astudillo, Peter I. Frazier"},{"Paper":"Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement","Tags":"multi-objective BO","Date":2021,"URL":"https://arxiv.org/abs/2105.08195","Venue":"NeurIPS","Authors":"Samuel Daulton, Maximilian Balandat, Eytan Bakshy"},{"Paper":"Multi-Objective Bayesian Optimization over High-Dimensional Search Spaces","Tags":"multi-objective BO","Date":2022,"URL":"https://arxiv.org/abs/2109.10964","Venue":"UAI","Authors":"Samuel Daulton, David Eriksson, Maximilian Balandat, Eytan Bakshy"},{"Paper":"Multi-Attribute Bayesian Optimization With Interactive Preference Learning","Tags":"preference BO","Date":2020,"URL":"https://arxiv.org/abs/1911.05934","Venue":"AISTATS","Authors":"Raul Astudillo, Peter I. Frazier"},{"Paper":"Preference Exploration for Efficient Bayesian Optimization with Multiple Outcomes","Tags":"preference BO","Date":2022,"URL":"https://arxiv.org/abs/2203.11382","Venue":"AISTATS","Authors":"Zhiyuan Jerry Lin, Raul Astudillo, Peter I. Frazier, Eytan Bakshy"},{"Paper":"qEUBO: A Decision-Theoretic Acquisition Function for Preferential Bayesian Optimization","Tags":"preference BO","Date":2023,"URL":"https://arxiv.org/abs/2303.15746","Venue":"AISTATS","Authors":"Raul Astudillo, Zhiyuan Jerry Lin, Eytan Bakshy, Peter I. Frazier"},{"Paper":"Preference-Aware Constrained Multi-Objective Bayesian Optimization","Tags":"multi-objective BO, preference BO","Date":2022,"URL":"https://arxiv.org/abs/2303.13034","Venue":"NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems","Authors":"Alaleh Ahmadianshalchi, Syrine Belakaria, Janardhan Rao Doppa"},{"Paper":"Preference Exploration for Efficient Bayesian Optimization with Multiple Outcomes","Tags":"preference BO","Date":2022,"URL":"https://arxiv.org/abs/2203.11382","Venue":"AISTATS","Authors":"Zhiyuan Jerry Lin, Raul Astudillo, Peter I. Frazier, Eytan Bakshy"},{"Paper":"Multi-Attribute Bayesian Optimization With Interactive Preference Learning","Tags":"preference BO","Date":2020,"URL":"https://arxiv.org/abs/1911.05934","Venue":"AISTATS","Authors":"Raul Astudillo, Peter I. Frazier"},{"Paper":"Causal Bayesian Optimization","Tags":"causal BO","Date":2020,"URL":"https://arxiv.org/abs/2005.11741","Venue":"AISTATS","Authors":"Virginia Aglietti, Xiaoyu Lu, Andrei Paleyes, Javier Gonz\xe1lez"},{"Paper":"Dynamic Causal Bayesian Optimization","Tags":"causal BO","Date":2021,"URL":"https://arxiv.org/abs/2110.13891","Venue":"NeurIPS","Authors":"Virginia Aglietti, Neil Dhir, Javier Gonz\xe1lez, Theodoros Damoulas"},{"Paper":"Model-based Causal Bayesian Optimization","Tags":"causal BO","Date":2023,"URL":"https://arxiv.org/abs/2211.10257","Venue":"ICLR","Authors":"Scott Sussex, Anastasiia Makarova, Andreas Krause"},{"Paper":"Functional Causal Bayesian Optimization","Tags":"causal BO","Date":2023,"URL":"https://arxiv.org/abs/2306.06409","Venue":"UAI","Authors":"Limor Gultchin, Virginia Aglietti, Alexis Bellot, Silvia Chiappa"},{"Paper":"Efficient Nonmyopic Bayesian Optimization via One-Shot Multi-Step Trees","Tags":"non-myopic decision making","Date":2020,"URL":"https://proceedings.neurips.cc/paper/2020/hash/d1d5923fc822531bbfd9d87d4760914b-Abstract.html","Venue":"NeurIPS","Authors":"Shali Jiang, Daniel R. Jiang, Maximilian Balandat, Brian Karrer, Jacob R. Gardner, Roman Garnett"},{"Paper":"Multi-Step Budgeted Bayesian Optimization with Unknown Evaluation Costs","Tags":"cost aware BO, non-myopic decision making","Date":2021,"URL":"https://arxiv.org/abs/2111.06537","Venue":"NeurIPS","Authors":"Raul Astudillo, Daniel R. Jiang, Maximilian Balandat, Eytan Bakshy, Peter I. Frazier"},{"Paper":"A Nonmyopic Approach to Cost-Constrained Bayesian Optimization","Tags":"cost aware BO, non-myopic decision making","Date":2021,"URL":"https://arxiv.org/abs/2106.06079","Venue":"UAI","Authors":"Eric Hans Lee, David Eriksson, Valerio Perrone, Matthias Seeger"},{"Paper":"Budgeted Bandit Problems with Continuous Random Costs","Tags":"cost aware BO","Date":2016,"URL":"https://proceedings.mlr.press/v45/Xia15.html","Venue":"ACML","Authors":"Yingce Xia, Wenkui Ding, Xu-Dong Zhang, Nenghai Yu, Tao Qin"},{"Paper":"Budgeted Multi\u2013Armed Bandit in Continuous Action\\nSpace","Tags":"cost aware BO","Date":2016,"URL":"https://dl.acm.org/doi/pdf/10.3233/978-1-61499-672-9-560","Venue":"ECAI","Authors":"Francesco Trovo, Stefano Paladino, Marcello Restelli, Nicola Gatti"},{"Paper":"Efficient Nonmyopic Active Search","Tags":"generalizations of BO, non-myopic decision making","Date":2017,"URL":"http://proceedings.mlr.press/v70/jiang17d.html","Venue":"ICML","Authors":"Shali Jiang, Gustavo Malkomes, Geoff Converse, Alyssa Shofner, Benjamin Moseley, Roman Garnett"},{"Paper":"Bayesian Algorithm Execution: Estimating Computable Properties of Black-box Functions Using Mutual Information","Tags":"generalizations of BO","Date":2021,"URL":"https://arxiv.org/abs/2104.09460","Venue":"ICML","Authors":"Willie Neiswanger, Ke Alexander Wang, Stefano Ermon"},{"Paper":"Bayesian Optimization with Conformal Coverage Guarantees\\n","Tags":"generalizations of BO","Date":2023,"URL":"https://arxiv.org/abs/2210.12496","Venue":"AISTATS","Authors":"Samuel Stanton, Wesley Maddox, Andrew Gordon Wilson"},{"Paper":"Bayesian Optimization with Inequality Constraints","Tags":"constrained BO","Date":2014,"URL":"http://proceedings.mlr.press/v32/gardner14.pdf","Venue":"ICML","Authors":"Jacob R. Gardner, Matt J. Kusner, Zhixiang Xu, Kilian Q. Weinberger, John P. Cunningham"},{"Paper":"Bayesian Optimization over Discrete and Mixed Spaces via Probabilistic Reparameterization","Tags":"mixed-space BO","Date":2022,"URL":"https://arxiv.org/abs/2210.10199","Venue":"NeurIPS","Authors":"Samuel Daulton, Xingchen Wan, David Eriksson, Maximilian Balandat, Michael A. Osborne, Eytan Bakshy"}]')},82:function(e,t){e.exports="data:image/png;base64,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"},83:function(e,t,a){e.exports=a(288)}},[[83,1,2]]]);
//# sourceMappingURL=main.5bcab4e6.chunk.js.map